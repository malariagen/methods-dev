{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See email from Jim 23/03/2016 10:32 for details of VR-track setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Plan\n",
    "- Create various setups (see Dushi email 02/10/2015 16:47)\n",
    "    - vrpipe-setup —based_on\n",
    "        - pf_pdna_import\n",
    "        - pf3kgatk_mapping\n",
    "    - wait for Dushi before running pf3kgatk_combine_gvcfs\n",
    "- output to /lustre/scratch109/malaria/WillH_1\n",
    "- final output to /nfs/team112_internal/production/release_build/Pf/WillH_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.4.3 |Anaconda 2.2.0 (64-bit)| (default, Mar  6 2015, 12:03:53) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "numpy 1.9.2\n",
      "scipy 0.15.1\n",
      "pandas 0.15.2\n",
      "numexpr 2.3.1\n",
      "pysam 0.8.3\n",
      "petl 1.0.11\n",
      "petlx 1.0.3\n",
      "vcf 0.6.7\n",
      "h5py 2.4.0\n",
      "tables 3.1.1\n",
      "vcfplt 0.8\n"
     ]
    }
   ],
   "source": [
    "%run standard_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RELEASE_DIR = '/nfs/team112_internal/production/release_build/Pf/WillH_1'\n",
    "RESOURCES_DIR = '%s/resources' % RELEASE_DIR\n",
    "\n",
    "GENOME_FN = \"/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\"\n",
    "SNPEFF_DIR = \"/lustre/scratch109/malaria/pf3k_methods/resources/snpEff\"\n",
    "REGIONS_FN = \"/nfs/team112_internal/rp7/src/github/malariagen/pf-crosses/meta/regions-20130225.bed.gz\"\n",
    "\n",
    "RELEASE_METADATA_FN = \"%s/Pf_WillH_1_sample_metadata.txt\" % RELEASE_DIR\n",
    "WG_VCF_FN = \"%s/vcf/Pf_WillH_1.vcf.gz\" % RELEASE_DIR\n",
    "\n",
    "BCFTOOLS = '/nfs/team112_internal/rp7/src/github/malariagen/methods-dev/pf3k_techbm/opt_4/bcftools/bcftools'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/team112_internal/production/release_build/Pf/WillH_1/vcf/Pf_WillH_1.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "print(WG_VCF_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chromosomes = [\"Pf3D7_%02d_v3\" % x for x in range(1, 15, 1)] + [\n",
    "    'Pf3D7_API_v3', 'Pf_M76611'\n",
    "]\n",
    "chromosome_vcfs = [\"%s/vcf/SNP_INDEL_%s.combined.filtered.vcf.gz\" % (RELEASE_DIR, x) for x in chromosomes]\n",
    "# print(chromosome_vcfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(RESOURCES_DIR):\n",
    "    os.makedirs(RESOURCES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp {GENOME_FN}* {RESOURCES_DIR}\n",
    "!cp -R {SNPEFF_DIR} {RESOURCES_DIR}\n",
    "!cp -R {REGIONS_FN} {RESOURCES_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VRTrack setup (Jim)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mkdir /nfs/team112_internal/production/release_build/Pf/WillH_1\n",
    "cd /nfs/team112_internal/production/release_build/Pf/WillH_1\n",
    "\n",
    "# build manifest of study/sample/library/lane for vrtrack to load\n",
    "pf_from_solaris.sh > ~/pf_files_20160323\n",
    "\n",
    "foreach ox(`cat Antoine_samples_vrpipe2.txt`)\n",
    "grep -w $ox ~/pf_files_20160323 >> Antoine_samples_meta.tab\n",
    "end\n",
    "\n",
    "# make database and load schema\n",
    "create database pipe_pf_antoine_vrtrack\n",
    "perl -MVRTrack::VRTrack -e 'foreach (VRTrack::VRTrack->schema()) {print}'|mysql -u vrtrack_rw -p -hvm-mii-malvrp -P3414  pipe_pf_antoine_vrtrack\n",
    "\n",
    "# load manifest into database\n",
    "load_vrtrack_v2.pl --infile Antoine_samples_meta.tab —database pipe_pf_antoine_vrtrack --species 'Plasmodium falciparum' --taxon 5833 —unacc\n",
    "\n",
    "# done!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vrpipe-setup --based_on pf_pdna_import\n",
    " --- Pipeline Setup 'pf_pdna_import' (id 652 for user jws) ---\n",
    "Pipeline: bam_import_from_irods_v2 | 2 steps | Copy bam or cram files stored in iRODs to local disc; removes spatial filter failing, secondary, supplementary and qc fail reads; outputs new bam\n",
    "PipelineSetup options:\n",
    "    cleanup => 1\n",
    "    estimated_filtered_percentage => 10\n",
    "    filter_flag => 2816\n",
    "    ichksum_exe => ichksum\n",
    "    iget_exe => iget\n",
    "    iquest_exe => iquest\n",
    "    irods_get_zone => seq\n",
    "    samtools_exe => /software/solexa/pkg/samtools/samtools-1.2/samtools\n",
    "PipelineSetup output root: /lustre/scratch111/malaria/pdna/output\n",
    "Output file unix group: team112\n",
    "DataSource: 470 | vrtrack | lane_bams | pipe_pf_pdna_vrtrack\n",
    "    local_root_dir => /lustre/scratch111/malaria/pdna/input\n",
    "\n",
    "There are a total of 375 Data Elements in the datasource to work on, and 0 elements are incomplete\n",
    "Pipeline currently 100% complete!\n",
    "------\n",
    "\n",
    "malsrv3[rp7]7: vrpipe-setup --based_on pf_pdna_import\n",
    "Based on PipelineSetup 652, your new setup will use the pipeline 'bam_import_from_irods_v2'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (irods_get_files_by_basename - Get files out of iRODs and store them on local disc. Tries to find the files in iRODs based on the basenames of the input files.), which expects:\n",
    "\t\tFile type = any (file paths that do not exist yet - the basename will be used to find the file in iRODs, and the file will be saved at this full path)\n",
    "\t\tNumber of files = 1..unlimited (and they don't have to exist yet)\n",
    "\t\tFiles must also have the following metadata associated with them (so be sure to pick a DataSource capable of adding this metadata):\n",
    "\t\t\texpected_md5 => the md5 checksum the file is supposed to have (optional)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [10]: 10\n",
    "vrtrack DataSources have a source described as:\n",
    "The name of the VRTrack database; assumes your database connection details are held in the normal set of VRTrack-related environment variables\n",
    "Supply the source [pipe_pf_pdna_vrtrack]: pipe_pf_antoine_vrtrack\n",
    "\n",
    "1. analysis_genome_studio (An element will comprise all the genome studio files (gtc or idat) for an analysis, and the files will have all relevant available metadata associated with them. Valid keys are: project, study, species, population, individual, sample, platform and library.)\n",
    "2. lane_fastqs (An element will comprise all the fastqs for a single lane, and the fastq files will have all relevant available metadata associated with them. The group_by_metadata option takes a '|' separated list of metadata keys by which dataelements will be grouped. e.g. group_by_metadata => 'sample|platform|library' will group all bams with the same sample, platform and library into one dataelement. Valid keys are: project, study, species, population, individual, sample, platform and library.)\n",
    "3. lane_bams (An element will comprise all the bams for a single lane, and the bam files will have all relevant available metadata associated with them. The group_by_metadata option takes a '|' separated list of metadata keys by which dataelements will be grouped. e.g. group_by_metadata => 'sample|platform|library' will group all bams with the same sample, platform and library into one dataelement. Valid keys are: project, study, species, population, individual, sample, platform and library.)\n",
    "4. lane_improved_bams (An element will comprise all the bams output by the VRPipe improvement pipeline for a single lane, and the bam files will have all relevant available metadata associated with them. The group_by_metadata option takes a '|' separated list of metadata keys by which dataelements will be grouped. e.g. group_by_metadata => 'sample|platform|library' will group all bams with the same sample, platform and library into one dataelement. Valid keys are: project, study, species, population, individual, sample, platform and library.)\n",
    "5. lanes (An element will comprise the name of a lane (only).)\n",
    "Pick one of the vrtrack DataSource methods from the above list <1|2|3|4|5> [3]: 3\n",
    "\n",
    "Please provide your options to the 'lane_bams' method:\n",
    "\tlocal_root_dir (REQUIRED, a Str|Dir) [/lustre/scratch111/malaria/pdna/input]: /lustre/scratch109/malaria/WillH_1/input\n",
    "\tproject_regex (optional, a Str): \n",
    "\tsample_regex (optional, a Str): \n",
    "\tlibrary_regex (optional, a Str): \n",
    "\tgt_status (optional, a Str): \n",
    "\tqc_status (optional, a Str): \n",
    "\tauto_qc_status (optional, a Str): \n",
    "\tnpg_qc_status (optional, a Str): \n",
    "\tgroup_by_metadata (optional, a Str): \n",
    "\n",
    "Please provide options for the 'bam_import_from_irods_v2' pipeline:\n",
    "\tirods_get_zone (optional, used by step irods_get_files_by_basename)\n",
    "\tthe zone (top level directory) where your data is stored in iRODs [seq]: \n",
    "\tichksum_exe (optional, used by step irods_get_files_by_basename)\n",
    "\tpath to your irods 'ichksum' executable [ichksum]: \n",
    "\tiquest_exe (optional, used by step irods_get_files_by_basename)\n",
    "\tpath to your irods 'iquest' executable [iquest]: \n",
    "\tiget_exe (optional, used by step irods_get_files_by_basename)\n",
    "\tpath to your irods 'iget' executable [iget]: \n",
    "\tfilter_flag (optional, used by step bam_or_cram_filter_reads)\n",
    "\tSamtools filter(-F) flag to use,default to spatial filter failing, secondary, supplementary and qc fail reads [2816]: \n",
    "\testimated_filtered_percentage (optional, used by step bam_or_cram_filter_reads)\n",
    "\tEstimated percentage of reads that will be filtered [10]: \n",
    "\tsamtools_exe (optional, used by step bam_or_cram_filter_reads)\n",
    "\tpath to your samtools executable [/software/solexa/pkg/samtools/samtools-1.2/samtools]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 1\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [1]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch111/malaria/pdna/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_import\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_import (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrtrack->lane_bams with source pipe_pf_antoine_vrtrack:\n",
    "\t\tlocal_root_dir => /lustre/scratch109/malaria/WillH_1/input\n",
    "\tPipeline: bam_import_from_irods_v2 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tcleanup => 1\n",
    "\t\testimated_filtered_percentage => 10\n",
    "\t\tfilter_flag => 2816\n",
    "\t\tichksum_exe => ichksum\n",
    "\t\tiget_exe => iget\n",
    "\t\tiquest_exe => iquest\n",
    "\t\tirods_get_zone => seq\n",
    "\t\tsamtools_exe => /software/solexa/pkg/samtools/samtools-1.2/samtools\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_import; Id: 729 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mapping"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vrpipe-setup --based_on pf3kgatk_mapping\n",
    " --- Pipeline Setup 'pf_pdna_mapping' (id 653 for user jws) ---\n",
    "Pipeline: bam_mapping_with_bwa_via_fastq | 11 steps | DEPRECATED: use bam_mapping_with_bwa_via_fastq_no_namesort instead. (Map reads in bam files to a reference genome with bwa fastq alignment)\n",
    "PipelineSetup options:\n",
    "    bam2fastq_exe => bam2fastq\n",
    "    bam_merge_keep_single_paired_separate => 1\n",
    "    bamcheck_exe => /nfs/team112_internal/production/tools/bin/bamcheck-2012-02-11\n",
    "    bwa_aln_options => -q 15\n",
    "    bwa_exe => /nfs/team112_internal/production/tools/bin/bwa-0.5.9\n",
    "    bwa_index_options => -a bwtsw\n",
    "    cleanup => 1\n",
    "    fastq_chunk_size => 1000000000\n",
    "    fastqcheck_exe => /nfs/team112_internal/production/tools/bin/fastqcheck\n",
    "    reference_assembly_name => Pf3D7_v3\n",
    "    reference_fasta => /lustre/scratch109/malaria/pfalciparum/resources/3D7_V3.fasta\n",
    "    reference_public_url => http://plasmodb.org/common/downloads/release-9.2/Pfalciparum3D7/fasta/data/PlasmoDB-9.2_Pfalciparum3D7_Genome.fasta\n",
    "    reference_species => P.falciparum\n",
    "    samtools_exe => /nfs/team112_internal/production/tools/bin/samtools_0.1.1.18\n",
    "    store_original_pg_chain => 1\n",
    "    uncompressed_fixed_bam_output => 0\n",
    "PipelineSetup output root: /lustre/scratch111/malaria/pdna/input\n",
    "Output file unix group: team112\n",
    "DataSource: 471 | vrpipe | all | pf_pdna_import[2]\n",
    "    filter_after_grouping => 1\n",
    "    maintain_element_grouping => 1\n",
    "\n",
    "There are a total of 375 Data Elements in the datasource to work on, and 0 elements are incomplete\n",
    "Pipeline currently 100% complete!\n",
    "------\n",
    "\n",
    "malsrv3[rp7]3: vrpipe-setup --based_on pf3kgatk_mapping\n",
    "Based on PipelineSetup 559, your new setup will use the pipeline 'bam_mapping_with_bwa_mem_via_fastq_v2'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t4 (bam_metadata - Takes a bam file and associates metadata with the file in the VRPipe database, making the bam file usable in other bam-related Steps), which expects:\n",
    "\t\tFile type = bam (bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\t5 (bam_shuffle_by_name - Shuffle and group alignments by name), which expects:\n",
    "\t\tFile type = bam (1 or more bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [4]: 8\n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source: WillH_import[2]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3>: 3\n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'bam_mapping_with_bwa_mem_via_fastq_v2' pipeline:\n",
    "\tsamtools_exe (optional, used by steps fasta_index, bam_shuffle_by_name, sam_to_fixed_bam_v2, bam_merge_lane_splits_v2, bam_index_v2)\n",
    "\tpath to your samtools executable [/nfs/team112_internal/production/tools/bin/samtools_1.2]: \n",
    "\treference_fasta (REQUIRED, used by steps fasta_index, sequence_dictionary, bwa_index, bwa_mem_fastq, sam_to_fixed_bam_v2)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: \n",
    "\treference_species (optional, used by step sequence_dictionary)\n",
    "\tspecies of the reference genome; defaults to being excluded [P.falciparum]: \n",
    "\treference_public_url (optional, used by step sequence_dictionary)\n",
    "\tpublic url that the reference_fasta can be accessed from; defaults to reference_fasta path [http://plasmodb.org/common/downloads/release-9.2/Pfalciparum3D7/fasta/data/PlasmoDB-9.2_Pfalciparum3D7_Genome.fasta]: \n",
    "\treference_assembly_name (optional, used by step sequence_dictionary)\n",
    "\tpublic name of the assembly, eg. NCBI37; defaults to being excluded [Pf3D7_v3]: \n",
    "\tbwa_index_options (optional, used by step bwa_index)\n",
    "\toptions to bwa index, excluding the reference fasta file [-a bwtsw]: \n",
    "\tbwa_exe (optional, used by steps bwa_index, bwa_mem_fastq)\n",
    "\tpath to your bwa executable [/nfs/team112_internal/production/tools/bin/bwa-0.7.12]: \n",
    "\tbamcheck_exe (optional, used by step bam_metadata)\n",
    "\tpath to your bamcheck executable [/nfs/team112_internal/production/tools/bin/bamcheck-2012-02-11]: \n",
    "\tstore_original_pg_chain (optional, used by step bam_metadata)\n",
    "\tIf your input bam was not created by VRPipe and will subsequently go through the bam_reheader step, keep this on; otherwise be sure to turn it off. [1]: \n",
    "\tbamshuf_options (optional, used by step bam_shuffle_by_name)\n",
    "\tcommand line options for samtools bamshuf, excluding the -O option: \n",
    "\tbam2fastq_exe (optional, used by step bam_to_fastq)\n",
    "\tpath to bam2fastq executable [/nfs/team112_internal/production/tools/bin/bam2fastq]: \n",
    "\tfastqcheck_exe (optional, used by step bam_to_fastq)\n",
    "\tpath to fastqcheck executable [/nfs/team112_internal/production/tools/bin/fastqcheck]: \n",
    "\tbam2fastq_opts (optional, used by step bam_to_fastq)\n",
    "\tbam2fastq options excluding --o: \n",
    "\tfastq_chunk_size (REQUIRED, used by step fastq_split)\n",
    "\twhen splitting fastq files into smaller chunks, this sets the size in bp; a good figure might be 1000000000 for a fast mapper [1000000000]: \n",
    "\tbwa_mem_options (optional, used by step bwa_mem_fastq)\n",
    "\toptions to bwa mem, excluding the input fastq, and reference [-M]: \n",
    "\tfixed_bam_seq_from_reference (optional, used by step sam_to_fixed_bam_v2)\n",
    "\tA boolean to choose whether sequence info is read from the reference -- set for mappers, such as smalt, which don't include this in output sam files: \n",
    "\tcompressed_bam_output (optional, used by step sam_to_fixed_bam_v2)\n",
    "\tA boolean to choose if the output bams from this step should be compressed [1]: \n",
    "\tbam_merge_keep_single_paired_separate (optional, used by step bam_merge_lane_splits_v2)\n",
    "\twhen merging bam files, separately merges single ended bam files and paired-end bam files, resulting in 2 merged bam files [1]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'delete_input_bams' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 5, 6, 7, 8, 9\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [1]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_mapping\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_mapping (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_import[2]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: bam_mapping_with_bwa_mem_via_fastq_v2 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tbam2fastq_exe => /nfs/team112_internal/production/tools/bin/bam2fastq\n",
    "\t\tbam_merge_keep_single_paired_separate => 1\n",
    "\t\tbamcheck_exe => /nfs/team112_internal/production/tools/bin/bamcheck-2012-02-11\n",
    "\t\tbwa_exe => /nfs/team112_internal/production/tools/bin/bwa-0.7.12\n",
    "\t\tbwa_index_options => -a bwtsw\n",
    "\t\tbwa_mem_options => -M\n",
    "\t\tcleanup => 1\n",
    "\t\tcompressed_bam_output => 1\n",
    "\t\tdelete_input_bams => 0\n",
    "\t\tfastq_chunk_size => 1000000000\n",
    "\t\tfastqcheck_exe => /nfs/team112_internal/production/tools/bin/fastqcheck\n",
    "\t\treference_assembly_name => Pf3D7_v3\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\treference_public_url => http://plasmodb.org/common/downloads/release-9.2/Pfalciparum3D7/fasta/data/PlasmoDB-9.2_Pfalciparum3D7_Genome.fasta\n",
    "\t\treference_species => P.falciparum\n",
    "\t\tsamtools_exe => /nfs/team112_internal/production/tools/bin/samtools_1.2\n",
    "\t\tstore_original_pg_chain => 1\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_mapping; Id: 730 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "One of these jobs initially failed. I tried manually rerunning with the following command (which appeared to run fine):\n",
    "\n",
    "/nfs/team112_internal/production/tools/bin/samtools_1.2 view -bSu \\\n",
    "/lustre/scratch109/malaria/WillH_1/output/d/f/f/e/590599/8_bwa_mem_fastq/7136_7_7.pe.3.sam \\\n",
    "| /nfs/team112_internal/production/tools/bin/samtools_1.2 sort -O bam -n \\\n",
    "-T ~/temp_setup730_debug/temp - \\\n",
    "| /nfs/team112_internal/production/tools/bin/samtools_1.2 fixmate -O bam /dev/stdin /dev/stdout \\\n",
    "| /nfs/team112_internal/production/tools/bin/samtools_1.2 sort -O bam \\\n",
    "-T ~/temp_setup730_debug/temp - \\\n",
    "| /nfs/team112_internal/production/tools/bin/samtools_1.2 calmd \\\n",
    "-b /dev/stdin /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta \\\n",
    "> ~/temp_setup730_debug/7136_7_7.pe.3.bam\n",
    "\n",
    "I then restarted with:\n",
    "\n",
    "vrpipe-submissions --setup 733 --failed --start_over --no_reportvrpipe-submissions --setup 730 --failed --start_over --no_report\n",
    "3 submissions passed your filter\n",
    "Here's the break-down by step name:\n",
    "\tsam_to_fixed_bam_v2 => 3\n",
    "\n",
    "Are you sure you want to reset these submissions? <y|n>: y\n",
    "Done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Mark duplicates"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vrpipe-setup --based_on pf3kgatk_mark_duplicates\n",
    "Based on PipelineSetup 562, your new setup will use the pipeline 'bam_mark_duplicates_v2'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (bam_mark_duplicates_v2 - Mark duplicates in a bam files using picard Version >= 1.137), which expects:\n",
    "\t\tFile type = bam (1 or more coordinate-sorted bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_mapping[bam_merge_lane_splits_v2:merged_lane_bams]|pf3kgatk_mapping_100bp[bam_mapping_by_samtools_bwa_mem_100bp:bwa_mem_bam_files]]: WillH_mapping[bam_merge_lane_splits_v2:merged_lane_bams]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [3]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'bam_mark_duplicates_v2' pipeline:\n",
    "\ttmp_dir (optional, used by steps bam_mark_duplicates_v2, build_bam_index)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tpicard_path (REQUIRED, used by steps bam_mark_duplicates_v2, build_bam_index)\n",
    "\tpath to Picard jar files [/nfs/team112_internal/production/tools/bin/picard-tools-1.137/]: \n",
    "\tjava_exe (optional, used by steps bam_mark_duplicates_v2, build_bam_index)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tmarkdup_options (optional, used by step bam_mark_duplicates_v2)\n",
    "\tcommand line options for Picard MarkDuplicates [ASSUME_SORTED=TRUE METRICS_FILE=/dev/null VALIDATION_STRINGENCY=SILENT]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'delete_input_bams' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [1]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_mark_duplicates         \n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_mark_duplicates (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_mapping[bam_merge_lane_splits_v2:merged_lane_bams]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: bam_mark_duplicates_v2 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tdelete_input_bams => 1\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\tmarkdup_options => ASSUME_SORTED=TRUE METRICS_FILE=/dev/null VALIDATION_STRINGENCY=SILENT\n",
    "\t\tpicard_path => /nfs/team112_internal/production/tools/bin/picard-tools-1.137/\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_mark_duplicates; Id: 731 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Indel realignment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_indel_realignment\n",
    "Based on PipelineSetup 563, your new setup will use the pipeline 'gatk_indel_realignment_gatk3_v2'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_realigner_target_creator_gatk3 - Creates target intervals file for known indel sites using gatk RealignerTargetCreator v3), which expects:\n",
    "\t\tFile type = bam (1 or more bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\t2 (gatk_indel_realigner_gatk3_v2 - Realigns reads around known indels using gatk IndelRealigner, also indexes aligned bam file,  gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = bam (1 or more bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_mark_duplicates[1]]: WillH_mark_duplicates[1]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [3]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'gatk_indel_realignment_gatk3_v2' pipeline:\n",
    "\ttmp_dir (optional, used by steps gatk_realigner_target_creator_gatk3, gatk_indel_realigner_gatk3_v2)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by steps gatk_realigner_target_creator_gatk3, gatk_indel_realigner_gatk3_v2)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgatk_realigner_target_creator_options (optional, used by step gatk_realigner_target_creator_gatk3)\n",
    "\tcommand line options for GATK RealignerTargetCreator, excluding reference, input, outpt files and RealignerTargetCreator task command: \n",
    "\tgatk_path (REQUIRED, used by steps gatk_realigner_target_creator_gatk3, gatk_indel_realigner_gatk3_v2)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by steps gatk_realigner_target_creator_gatk3, gatk_indel_realigner_gatk3_v2)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: \n",
    "\tgatk_key (REQUIRED, used by steps gatk_realigner_target_creator_gatk3, gatk_indel_realigner_gatk3_v2)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\tgatk_indel_realigner_options (optional, used by step gatk_indel_realigner_gatk3_v2)\n",
    "\tcommand line options for GATK IndelRealigner, excluding reference, target intervals, input, output files and IndelRealigner task command: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'delete_input_bams' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [1]: \n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 1\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [1]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_indel_realignment\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_indel_realignment (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_mark_duplicates[1]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: gatk_indel_realignment_gatk3_v2 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tcleanup => 1\n",
    "\t\tdelete_input_bams => 1\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_indel_realignment; Id: 732 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Base quality score recalibration (BQSR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_bqsr\n",
    "Based on PipelineSetup 564, your new setup will use the pipeline 'gatk_base_quality_score_recalibration_gatk3'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_base_recalibrator_gatk3 - Recalibrate quality scores using GATK BaseRecalibrator, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = bam (1 or more bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\t2 (gatk_print_reads_gatk3 - Produces realigned, recalibrated bam file using gatk PrintReads, also indexes bam, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = bam (1 or more bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_indel_realignment[gatk_indel_realigner_gatk3_v2:realigned_bam_files]]: WillH_indel_realignment[gatk_indel_realigner_gatk3_v2:realigned_bam_files]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [3]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'gatk_base_quality_score_recalibration_gatk3' pipeline:\n",
    "\ttmp_dir (optional, used by steps gatk_base_recalibrator_gatk3, gatk_print_reads_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by steps gatk_base_recalibrator_gatk3, gatk_print_reads_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgatk_base_recalibrator_options (optional, used by step gatk_base_recalibrator_gatk3)\n",
    "\tcommand line options for GATK BaseRecalibrator, excluding reference, input, output files and BaseRecalibrator task command, specify list of -knownSites along with other options here [-knownSites /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/7g8_gb4.combined.final.vcf.gz -knownSites /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/hb3_dd2.combined.final.vcf.gz -knownSites /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/3d7_hb3.combined.final.vcf.gz]: \n",
    "\tgatk_path (REQUIRED, used by steps gatk_base_recalibrator_gatk3, gatk_print_reads_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by steps gatk_base_recalibrator_gatk3, gatk_print_reads_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: \n",
    "\tgatk_key (REQUIRED, used by steps gatk_base_recalibrator_gatk3, gatk_print_reads_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\tgatk_print_reads_options (optional, used by step gatk_print_reads_gatk3)\n",
    "\tcommand line options for GATK PrintReads; excludes reference, BQSR, input, output files and PrintReads task command: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'delete_input_bams' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [1]: \n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 1\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [1]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_bqsr\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_bqsr (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_indel_realignment[gatk_indel_realigner_gatk3_v2:realigned_bam_files]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: gatk_base_quality_score_recalibration_gatk3 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tcleanup => 1\n",
    "\t\tdelete_input_bams => 1\n",
    "\t\tgatk_base_recalibrator_options => -knownSites /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/7g8_gb4.combined.final.vcf.gz -knownSites /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/hb3_dd2.combined.final.vcf.gz -knownSites /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/3d7_hb3.combined.final.vcf.gz\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_bqsr; Id: 733 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Four of these jobs initially failed. I initially tried manually running the commands seen in the output of:\n",
    "vrpipe-submissions --setup 733 --failed\n",
    "on both malsrv3, and as an interactive job on the farm (bsub -Ip /bin/bash on farm3-login)\n",
    "but the jobs appeared to stop without completing or error message\n",
    "\n",
    "I then restarted with:\n",
    "\n",
    "vrpipe-submissions --setup 733 --failed --start_over --no_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Merge lanes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_mergelanes\n",
    "Based on PipelineSetup 566, your new setup will use the pipeline 'bam_merge_lanes_and_fix_rgs_v2'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (bam_strip_tags - Strips tags from bam files), which expects:\n",
    "\t\tFile type = bam (1 or more bam files to strip tags from)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_bqsr[gatk_print_reads_gatk3:recalibrated_bam_files]]: WillH_bqsr[gatk_print_reads_gatk3:recalibrated_bam_files]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [1]: \n",
    "\n",
    "Please provide your options to the 'group_by_metadata' method:\n",
    "\tmetadata_keys (REQUIRED, a Str) [sample]: sample|library\n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'bam_merge_lanes_and_fix_rgs_v2' pipeline:\n",
    "\tbam_tags_to_strip (optional, used by step bam_strip_tags)\n",
    "\tTags to strip from the BAM files. Give tags separated by spaces. [OQ XM XG XO]: \n",
    "\ttmp_dir (optional, used by steps bam_add_readgroup_v2, bam_merge, bam_mark_duplicates_v2)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tpicard_path (REQUIRED, used by steps bam_add_readgroup_v2, bam_merge, bam_mark_duplicates_v2)\n",
    "\tpath to Picard jar files [/nfs/team112_internal/production/tools/bin/picard-tools-1.137/]: \n",
    "\tjava_exe (optional, used by steps bam_add_readgroup_v2, bam_merge, bam_mark_duplicates_v2)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tpicard_add_readgroups_options (optional, used by step bam_add_readgroup_v2)\n",
    "\toptions for picard AddOrReplaceReadGroups [VALIDATION_STRINGENCY=SILENT COMPRESSION_LEVEL=0]: \n",
    "\treadgroup_sm_from_metadata_key (optional, used by step bam_add_readgroup_v2)\n",
    "\tThe SM of the readgroup will come from metadata associated with the bam; this option chooses which metadata key to get the value from [sample]: \n",
    "\tbam_merge_maximum_files (optional, used by step bam_merge)\n",
    "\tset the maximum number of files to merge in one go; eg. if there are 100 bams to merge and you set this to 40, 3 output bams will result, being merges of 40, 40 and 20 of the input bams (defaults to infinity): \n",
    "\tmerge_sam_files_options (optional, used by step bam_merge)\n",
    "\toptions for picard MergeSamFiles [VALIDATION_STRINGENCY=SILENT]: \n",
    "\tbam_merge_keep_single_paired_separate (optional, used by step bam_merge)\n",
    "\twhen merging bam files, separately merges single ended bam files and paired-end bam files, resulting in 2 merged bam files [1]: \n",
    "\tmarkdup_options (optional, used by step bam_mark_duplicates_v2)\n",
    "\tcommand line options for Picard MarkDuplicates [ASSUME_SORTED=TRUE METRICS_FILE=/dev/null VALIDATION_STRINGENCY=SILENT]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'delete_input_bams' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: 1\n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 1, 2, 3\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [1]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server): team112\n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_mergelanes\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_mergelanes (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->group_by_metadata with source WillH_bqsr[gatk_print_reads_gatk3:recalibrated_bam_files]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmetadata_keys => sample|library\n",
    "\tPipeline: bam_merge_lanes_and_fix_rgs_v2 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tbam_merge_keep_single_paired_separate => 1\n",
    "\t\tbam_tags_to_strip => OQ XM XG XO\n",
    "\t\tcleanup => 1\n",
    "\t\tdelete_input_bams => 1\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\tmarkdup_options => ASSUME_SORTED=TRUE METRICS_FILE=/dev/null VALIDATION_STRINGENCY=SILENT\n",
    "\t\tmerge_sam_files_options => VALIDATION_STRINGENCY=SILENT\n",
    "\t\tpicard_add_readgroups_options => VALIDATION_STRINGENCY=SILENT COMPRESSION_LEVEL=0\n",
    "\t\tpicard_path => /nfs/team112_internal/production/tools/bin/picard-tools-1.137/\n",
    "\t\treadgroup_sm_from_metadata_key => sample\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_mergelanes; Id: 734 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Merge libraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf_pdna_gatk_mergelibs\n",
    "Based on PipelineSetup 693, your new setup will use the pipeline 'bam_merge_v3'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (bam_merge_v2 - Merges bam files using Picard MergeSamFiles,using picard Version >= 1.137), which expects:\n",
    "\t\tFile type = bam (1 or more bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\t\tFiles must also have the following metadata associated with them (so be sure to pick a DataSource capable of adding this metadata):\n",
    "\t\t\tbases => total number of base pairs (optional)\n",
    "\t\t\tcenter_name => center name, or comma separated list of center names if merged (optional)\n",
    "\t\t\tlane => lane name, or comma separated list of lane names if merged (optional)\n",
    "\t\t\tlibrary => library name, or comma separated list of library names if merged (optional)\n",
    "\t\t\tpaired => 0=unpaired reads were mapped; 1=paired reads were mapped (REQUIRED)\n",
    "\t\t\tplatform => sequencing platform, or comma separated list of platform names if merged (optional)\n",
    "\t\t\treads => total number of reads (sequences) (REQUIRED)\n",
    "\t\t\tsample => sample name, or comma separated list of sample names if merged (optional)\n",
    "\t\t\tstudy => name of the study, or comma separated list of study names if merged (optional)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf_pdna_gatk_mergelanes[bam_mark_duplicates_v2:markdup_bam_files]]: WillH_mergelanes[bam_mark_duplicates_v2:markdup_bam_files]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [1]: \n",
    "\n",
    "Please provide your options to the 'group_by_metadata' method:\n",
    "\tmetadata_keys (REQUIRED, a Str) [sample]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'bam_merge_v3' pipeline:\n",
    "\ttmp_dir (optional, used by step bam_merge_v2)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tpicard_path (REQUIRED, used by step bam_merge_v2)\n",
    "\tpath to Picard jar files [/nfs/team112_internal/production/tools/bin/picard-tools-1.137/]: \n",
    "\tbam_merge_maximum_files (optional, used by step bam_merge_v2)\n",
    "\tset the maximum number of files to merge in one go; eg. if there are 100 bams to merge and you set this to 40, 3 output bams will result, being merges of 40, 40 and 20 of the input bams (defaults to infinity): \n",
    "\tjava_exe (optional, used by step bam_merge_v2)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tmerge_sam_files_options (optional, used by step bam_merge_v2)\n",
    "\toptions for picard MergeSamFiles [VALIDATION_STRINGENCY=SILENT]: \n",
    "\tbam_merge_keep_single_paired_separate (optional, used by step bam_merge_v2)\n",
    "\twhen merging bam files, separately merges single ended bam files and paired-end bam files, resulting in 2 merged bam files [1]: \n",
    "\tsamtools_exe (optional, used by step bam_index_v2)\n",
    "\tpath to your samtools executable [/nfs/team112_internal/production/tools/bin/samtools_1.2]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'delete_input_bams' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [1]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch110/malaria/pdna_gatk/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_mergelibs\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_mergelibs (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->group_by_metadata with source WillH_mergelanes[bam_mark_duplicates_v2:markdup_bam_files]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmetadata_keys => sample\n",
    "\tPipeline: bam_merge_v3 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tbam_merge_keep_single_paired_separate => 1\n",
    "\t\tdelete_input_bams => 1\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\tmerge_sam_files_options => VALIDATION_STRINGENCY=SILENT\n",
    "\t\tpicard_path => /nfs/team112_internal/production/tools/bin/picard-tools-1.137/\n",
    "\t\tsamtools_exe => /nfs/team112_internal/production/tools/bin/samtools_1.2\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_mergelibs; Id: 735 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sample bam summaries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf_pdna_gatk_samtools_bam_stats_gatk_callable_loci_gatk3\n",
    "Based on PipelineSetup 694, your new setup will use the pipeline 'samtools_bam_stats_gatk_callable_loci_gatk3'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (samtools_bam_stats - Creates a file of stats on a bam file, and also adds metada into bam file.), which expects:\n",
    "\t\tFile type = bam (bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\t2 (gatk_callable_loci_gatk3 - Run GATK CallableLoci v3 on a BAM, generating a summary file and output file), which expects:\n",
    "\t\tFile type = bam (1 or more bam files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf_pdna_gatk_mergelibs[1]]: WillH_mergelibs[1]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [3]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'samtools_bam_stats_gatk_callable_loci_gatk3' pipeline:\n",
    "\texome_targets_file (optional, used by step samtools_bam_stats)\n",
    "\tabsolute path to a file describing the targets/baits used for exome pulldown (tab-delimited [chr,start,end], where start is 1-based, and end is inclusive): \n",
    "\tsamtools_stats_options (optional, used by step samtools_bam_stats)\n",
    "\toptions to samtools stats, excluding -r and -t (which are set by reference_fasta and exome_targets_file options): \n",
    "\tsamtools_exe (optional, used by step samtools_bam_stats)\n",
    "\tpath to your samtools executable [/nfs/team112_internal/production/tools/bin/samtools_1.2]: \n",
    "\treference_fasta (REQUIRED, used by steps samtools_bam_stats, gatk_callable_loci_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch110/malaria/pdna_gatk/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\ttmp_dir (optional, used by step gatk_callable_loci_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by step gatk_callable_loci_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_callable_loci_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5]: \n",
    "\tgatk_key (REQUIRED, used by step gatk_callable_loci_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\tcallable_loci_options (REQUIRED, used by step gatk_callable_loci_gatk3)\n",
    "\tOptions for GATK CallableLoci, excluding -R,-I,-o,-summary [--minDepth 5]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 2\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch110/malaria/pdna_gatk/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_sample_bam_summary\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_sample_bam_summary (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_mergelibs[1]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: samtools_bam_stats_gatk_callable_loci_gatk3 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tcallable_loci_options => --minDepth 5\n",
    "\t\tcleanup => 0\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tsamtools_exe => /nfs/team112_internal/production/tools/bin/samtools_1.2\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_sample_bam_summary; Id: 736 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Symlinks for sample bams"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "cd /nfs/team112_internal/production/release_build/Pf/WillH_1\n",
    "mkdir bam\n",
    "vrpipe-output --setup WillH_mergelibs --step 1 --output_dir /nfs/team112_internal/production/release_build/Pf/WillH_1/bam --basename_from_metadata %sample% --pretend | less -S\n",
    "vrpipe-output --setup WillH_mergelibs --step 1 --output_dir /nfs/team112_internal/production/release_build/Pf/WillH_1/bam --basename_from_metadata %sample%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#HaplotypeCaller"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because of a wrinkle in vrpipe, we need to create a fofn of sample bams at this stage\n",
    "See email from Dushi 24/03/2016 11:51 for further details\n",
    "\n",
    "vrpipe-fileinfo --setup WillH_mergelibs --step 1 > /lustre/scratch109/malaria/WillH_1/meta/WillH_mergelibs.output\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Want to make the following changes with respect to previous pipeline runs\n",
    "- Run in haploid mode\n",
    "\n",
    "- Add \"--read_filter ReassignOriginalMQAfterIndelRealignment\" to HaplotypeCaller\n",
    "However, this failed as ReassignOriginalMQAfterIndelRealignment is not a valid value. Need to chase up with GATK team\n",
    "\n",
    "vrpipe-setup --based_on pf3kgatk_haplotype_caller\n",
    "Based on PipelineSetup 569, your new setup will use the pipeline 'snp_calling_gatk3_haplotype_caller_v2'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_haplotype_caller_gatk3_v2 - Run GATK HaplotypeCaller for all bams belongs to a sample, generating one compressed gVCF per sample/region bams. Also indexes vcf file, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = bam (1 or more bam files to call variants)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [3]: \n",
    "fofn_with_genome_chunking DataSources have a source described as:\n",
    "The path to a file with one absolute file path per line.\n",
    "Supply the source [/lustre/scratch109/malaria/pf3k_methods/input/pf3kgatk_mergelibs.fofn]: /lustre/scratch109/malaria/WillH_1/meta/WillH_mergelibs.output\n",
    "\n",
    "1. group_all (All files in the file will be grouped into a single element. Each dataelement will be duplicated in chunks across the genome. The option 'reference_index' is the absolute path to the fasta index (.fai) file associated with the reference fasta file, 'chunk_override_file' is a file defining chunk specific options that may be overridden (required, but may point to an empty file), 'chunk_size' the size of the chunks in bp, 'chunk_overlap' defines how much overlap to have beteen chunks, 'chrom_list' (a space separated list) will restrict to specified the chromosomes (must match chromosome names in dict file), 'ploidy' is an optional file specifying the ploidy to be used for males and females in defined regions of the genome, eg {default=>2, X=>[{ from=>1, to=>60_000, M=>1 },{ from=>2_699_521, to=>154_931_043, M=>1 },],Y=>[{ from=>1, to=>59_373_566, M=>1, F=>0 }]}.)\n",
    "2. all (Each element will correspond to a single file from the file. Each dataelement will be duplicated in chunks across the genome. The option 'reference_index' is the absolute path to the fasta index (.fai) file associated with the reference fasta file, 'chunk_override_file' is a file defining chunk specific options that may be overridden (required, but may point to an empty file), 'chunk_size' the size of the chunks in bp, 'chunk_overlap' defines how much overlap to have beteen chunks, 'chrom_list' (a space separated list) will restrict to specified the chromosomes (must match chromosome names in dict file), 'ploidy' is an optional file specifying the ploidy to be used for males and females in defined regions of the genome, eg {default=>2, X=>[{ from=>1, to=>60_000, M=>1 },{ from=>2_699_521, to=>154_931_043, M=>1 },],Y=>[{ from=>1, to=>59_373_566, M=>1, F=>0 }]}.)\n",
    "Pick one of the fofn_with_genome_chunking DataSource methods from the above list <1|2> [2]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\treference_index (REQUIRED, a Str|File) [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta.fai]: \n",
    "\tchunk_override_file (REQUIRED, a Str|File) [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum_chunk_override]: \n",
    "\tchunk_size (REQUIRED, a Int) [4000000]: \n",
    "\tchunk_overlap (REQUIRED, a Int): 0\n",
    "\tchrom_list (optional, a Str): \n",
    "\tploidy (optional, a Str|File): \n",
    "\n",
    "Please provide options for the 'snp_calling_gatk3_haplotype_caller_v2' pipeline:\n",
    "\ttmp_dir (optional, used by step gatk_haplotype_caller_gatk3_v2)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by step gatk_haplotype_caller_gatk3_v2)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tsites_file (optional, used by step gatk_haplotype_caller_gatk3_v2)\n",
    "\tSites file path: \n",
    "\tminimum_records (optional, used by step gatk_haplotype_caller_gatk3_v2)\n",
    "\tMinimum number of records expected in output VCF. Not recommended if using genome chunking [0]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_haplotype_caller_gatk3_v2)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by step gatk_haplotype_caller_gatk3_v2)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: \n",
    "\thaplotype_caller_options (REQUIRED, used by step gatk_haplotype_caller_gatk3_v2)\n",
    "\tOptions for GATK HaplotypeCaller, excluding -R,-I,-o,sites file [--emitRefConfidence GVCF --variant_index_type LINEAR --variant_index_parameter 128000 --max_alternate_alleles 6]: --emitRefConfidence GVCF --variant_index_type LINEAR --variant_index_parameter 128000 --max_alternate_alleles 6  --sample_ploidy 1 --annotation GenotypeSummaries --annotation LikelihoodRankSumTest --annotation MappingQualityZero\n",
    "\tgatk_key (REQUIRED, used by step gatk_haplotype_caller_gatk3_v2)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'delete_input_bams' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server): team112\n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_haplotype_caller\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_haplotype_caller (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: fofn_with_genome_chunking->all with source /lustre/scratch109/malaria/WillH_1/meta/WillH_mergelibs.output:\n",
    "\t\tchunk_overlap => 0\n",
    "\t\tchunk_override_file => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum_chunk_override\n",
    "\t\tchunk_size => 4000000\n",
    "\t\treference_index => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta.fai\n",
    "\tPipeline: snp_calling_gatk3_haplotype_caller_v2 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tdelete_input_bams => 0\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\thaplotype_caller_options => --emitRefConfidence GVCF --variant_index_type LINEAR --variant_index_parameter 128000 --max_alternate_alleles 6  --sample_ploidy 1 --annotation GenotypeSummaries --annotation LikelihoodRankSumTest --annotation MappingQualityZero\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\tminimum_records => 0\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Combine gvcfs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vrpipe-setup \n",
    "\n",
    "1. 1000genomes_454_mapping_with_improvement [Map (with improvement) LS454 reads in fastq files on the DCC ftp site to a reference genome with smalt]\n",
    "2. 1000genomes_illumina_mapping_with_improvement [Map (with improvement) Illumina reads in fastq files on the DCC ftp site to a reference genome with bwa]\n",
    "3. 1000genomes_release [Create 1000 genomes release files]\n",
    "4. archive_files [Safely move files from one disc to a pool of one or more other discs, eg. for archival purposes. (the output_root option for this pipeline is meaningless)]\n",
    "5. bam2som [Filter BAM files to SNP-o-matic]\n",
    "6. bam_base_quality_score_recalibration_gatk_v2 [Recalibrate base quality scores, including insertion and deletion error models with GATK BaseRecalibrator v2]\n",
    "7. bam_check [Outputs bamcheck file containing stats on bam file]\n",
    "8. bam_coverage [runs bam depth stats and plots pipeline]\n",
    "9. bam_cram_bam_test_pipeline [a pipeline for testing conversion of bam to cram and cram to bam]\n",
    "10. bam_depth [Outputs base depth from bam file into depth.gz file]\n",
    "11. bam_depth_2 [runs depth stats steps]\n",
    "12. bam_depth_overlay_2 [runs bam_depth_overlay_2 step]\n",
    "13. bam_depth_overlay_plot_2 [runs bam_depth_overlay_plot_2 step]\n",
    "14. bam_depth_plot_2 [runs bam_depth_plot_2 step]\n",
    "15. bam_depth_plot_compare_regions_2 [runs bam_depth_plot_compare_regions_2 step]\n",
    "16. bam_depth_plot_regions_2 [runs bam_depth_plot_regions_2 step]\n",
    "17. bam_filter_genotype [Filter BAM files by candidate SNP list and genotype stringently]\n",
    "18. bam_genotype_checking [Check that the genotype of bam files matches the genotype of the samples they claim to be of.]\n",
    "19. bam_hq_snps_quality [Outputs BAM base depth coverage for each SNP in a SNP list by executing bam_hq_snps_quality step]\n",
    "20. bam_htscmd_genotype_checking [Uses htscmd gtcheck to check that the genotype of bam files matches the genotype of the samples they claim to be of.]\n",
    "21. bam_import_from_irods [Copy bam files stored in iRODs to local disc.]\n",
    "22. bam_import_from_irods_and_vrtrack_qc [Copy bam files stored in iRODs to local disc, generate QC stats and graphs and update the VRTrack db.]\n",
    "23. bam_import_from_irods_v2 [Copy bam or cram files stored in iRODs to local disc; removes spatial filter failing, secondary, supplementary and qc fail reads; outputs new bam]\n",
    "24. bam_import_internal [Simple pipeline to move bam files between disks]\n",
    "25. bam_improvement [Improves bam files by realigning around known indels, recalibrating quality scores and adding NM and BQ tags]\n",
    "26. bam_improvement_and_update_vrtrack [Improves bam files by realigning around known indels, recalibrating quality scores and adding NM and BQ tags; adds the resulting bam to your VRTrack db]\n",
    "27. bam_improvement_and_update_vrtrack_no_recal [Improves bam files by realigning around known indels, and adding NM and BQ tags; adds the resulting bam to your VRTrack db. Does no quality score recalibration, useful when dealing with species that diverge from reference greatly or have no/few SNP calls]\n",
    "28. bam_improvement_and_update_vrtrack_phase1 [Improves bam files by realigning around known indels, fixing mate information, recalibrating quality scores and adding NM and BQ tags; adds the resulting bam to your VRTrack db]\n",
    "29. bam_improvement_no_recal [Improves bam files by realigning around known indels, and adding NM and BQ tags. Does no quality score recalibration, useful when dealing with species that diverge from reference greatly or have no/few SNP calls]\n",
    "30. bam_index [Index bam files]\n",
    "31. bam_lanelet_gt_check [Runs lanelet Genotype consistency check and updates bam metadata if GT is confirmed]\n",
    "32. bam_mapping_by_samtools_bwa_mem_100bp [Map reads in bam files to a reference genome with bwa-mem, downsampling sequence read lengths to 100bp, outputs coordinate sorted bam, using samtools, version >= 1.2, bwa >= 0.7.12]\n",
    "33. bam_mapping_with_bwa [Map reads in bam files to a reference genome with bwa. NB: this is unreliable and you may have better success with bam_mapping_with_bwa_via_fastq_no_namesort]\n",
    "34. bam_mapping_with_bwa_mem_via_fastq [Map reads in bam files to a reference genome with bwa-mem after grouping alignments based on name and converting to fastq]\n",
    "35. bam_mapping_with_bwa_mem_via_fastq_v2 [Map reads in bam files to a reference genome with bwa-mem after grouping alignments based on name and converting to fastq, using samtools, version >= 1.2, bwa >= 0.7.12]\n",
    "36. bam_mapping_with_bwa_via_fastq [DEPRECATED: use bam_mapping_with_bwa_via_fastq_no_namesort instead. (Map reads in bam files to a reference genome with bwa fastq alignment)]\n",
    "37. bam_mapping_with_bwa_via_fastq_no_namesort [Map reads in bam files to a reference genome with bwa fastq alignment]\n",
    "38. bam_mapping_with_stampy [Map reads in bam files to a reference genome with stampy (and bwa)]\n",
    "39. bam_mapping_with_stampy_divergent [Map reads in bam files to a reference genome with stampy, using a preliminary mapping and snp calling to determine the substitution rate to map with]\n",
    "40. bam_mark_duplicates [Marks duplicates in bam files using picard]\n",
    "41. bam_mark_duplicates_v2 [Marks duplicates and builds index of bam files using picard Version >= 1.137]\n",
    "42. bam_merge [Merge bam files together and index the results (suitable for merging library bams to the sample level, and \"merge-across\")]\n",
    "43. bam_merge_1000_genomes_libraries_with_split [Merge, reheader and split]\n",
    "44. bam_merge_and_split [Merge bam files together then split into chromosomal bams]\n",
    "45. bam_merge_lanes [Tag strip, merge and mark duplicates]\n",
    "46. bam_merge_lanes_and_fix_rgs [Tag strip, add/correct RG tags for all records, merge and mark duplicates]\n",
    "47. bam_merge_lanes_and_fix_rgs_v2 [PLS USE bam_merge_lanes_and_fix_rgs_v3: Tag strip, add/correct RG tags for all records, merge and mark duplicates]\n",
    "48. bam_merge_lanes_and_fix_rgs_v3 [Tag strip, add/correct RG tags for all records, merge and mark duplicates,using picard Version >= 1.137]\n",
    "49. bam_merge_multistage_with_metadata [Runs three iterations of the bam_merge step, adds metadata and Indexs bam files]\n",
    "50. bam_merge_v2 [PLS USE bam_merge_v3: Merge bam files together and index the results (suitable for merging library bams to the sample level, and \"merge-across\")]\n",
    "51. bam_merge_v3 [Merge bam files together and index the results (suitable for merging library bams to the sample level, and \"merge-across,using picard Version >= 1.137,samtools version >= 1.2\")]\n",
    "52. bam_qc_graphs_and_stats [Generates graphs and stats to describe bam files for quality-checking purposes.]\n",
    "53. bam_realignment_around_discovered_indels [Use GATK to discover possible indels in a bam, then realign in those regions.]\n",
    "54. bam_reduce_reads [Apply GATK ReduceReads to bam files]\n",
    "55. bam_spatial_filter [apply spatial filter to bams]\n",
    "56. bam_split [Split bams into chromosomal bams]\n",
    "57. bam_split_by_region_with_metada_for_snp_calling [Splits a BAM file into multiple BAM files, one for each genomic region specified. Includes by default 100 overlapping regions on both sides into chunk files, necessary for snp calling by postion.]\n",
    "58. bam_stats [Calculate stats on bam files]\n",
    "59. bcf_merge_prepared_multistage [Runs three iterations of the bcf_merge_prepared step]\n",
    "60. bis_seq_bismark [Bisulphite Sequencing Pipeline employing Bismark tools to gain methylation calls.]\n",
    "61. breakdancer_analysis [Run breakdancer structural variant detection]\n",
    "62. cnv_control_comparison [Reformat CNV files from penncnv or quantisnp into bed format, then compare sample CNV output to that of the control cell type. Produces output files of intersection between control and sample and sample minus contol (i.e. the diff)]\n",
    "63. conifer_analysis [Runs conifer analysis for grouped sets of exome bams, generating a SVD-ZRPKM values, cnv calls and associated plots for each group]\n",
    "64. convert_cram_bam_to_bam_using_samtools [Converts cram/bam files, removes spatial filter failing, secondary, qc fail and supplementary reads, necessary for other tools to work,  using samtools, version >= 1.2]\n",
    "65. convert_cram_bam_to_bam_using_samtools_without_filtering [Convert cram/bam files, with out applying any filters,  using samtools, version >= 1.2]\n",
    "66. convex_cnv_calling [Run CoNVex pipeline to Generate CNV calls from Read Depth and L2R files]\n",
    "67. convex_l2r_bp_generation [Run CoNVex pipeline to Generate L2R files from Read Depth files, and Breakpoint file, for subsequent CNV Calling pipeline]\n",
    "68. convex_plot_generation [Run CoNVex pipeline to Generate CNV call plots from set of Convex CNV calls]\n",
    "69. convex_read_depth_generation [Run CoNVex pipeline to Generate Read Depth files and add Sample metadata to bam files, for subsequent L2R Generation and CNV Calling pipelines]\n",
    "70. fastq_mapping_with_bwa [Map reads in fastq files to a reference genome with bwa]\n",
    "71. fastq_mapping_with_bwa_mem [Map reads in fastq files to a reference genome with bwa mem]\n",
    "72. fastq_mapping_with_smalt [Map reads in fastq files to a reference genome with smalt]\n",
    "73. freebayes [Runs freebayes]\n",
    "74. gatk_base_quality_score_recalibration_gatk3 [Executes GATK3 BaseRecalibrator, PrintReads using gatk version >= 3.4-46]\n",
    "75. gatk_callable_loci_gatk2 [Adds GATK CallableLoci stats into bam metadata]\n",
    "76. gatk_callable_loci_gatk3 [Adds GATK CallableLoci stats into bam metadata]\n",
    "77. gatk_combine_gvcfs_gatk3 [Runs gatk CombineGVCFs, gatk version >= 3.4-46]\n",
    "78. gatk_combine_gvcfs_gatk3_merge_prepared [Runs gatk_combine_gvcfs_gatk3_merge_prepared]\n",
    "79. gatk_combine_gvcfs_gatk3_merge_prepared_multistage [Runs three iterations of the gatk_combine_gvcfs_gatk3_merge_prepared]\n",
    "80. gatk_combine_variants_gatk3 [Combines 2 vcf files, one each for SNP and INDEL, both with having metadata value for variation_mode and chrom, using GATK CombineVariants v3, gatk version >= 3.4-46]\n",
    "81. gatk_indel_realignment_gatk3 [Executes GATK3s LeftAlignIndels, RealignerTargetCreator, IndelRealigner tasks to realign Indels on a given bam]\n",
    "82. gatk_indel_realignment_gatk3_v2 [Executes GATK3 RealignerTargetCreator, IndelRealigner tasks to realign Indels on a given bam, also indexes aligned bam file, gatk version >= 3.4-46]\n",
    "83. gatk_phase_1 [gatk best practices phase 1 pipeline]\n",
    "84. gatk_phase_2 [gatk best practices phase 2 pipeline]\n",
    "85. gatk_phase_3 [gatk best practices phase 3 pipeline]\n",
    "86. gatk_select_variants_apply_recalibration_for_indels_gatk3 [Runs gatk SelectVariants and ApplyRecalibration using gatk version >= 3.4-46]\n",
    "87. gatk_select_variants_apply_recalibration_for_snps_gatk3 [Runs gatk SelectVariants and ApplyRecalibration using gatk version >= 3.4-46]\n",
    "88. gatk_variant_filter_gatk3 [Runs gatk VariantFiltration, gatk version >= 3.4-46]\n",
    "89. gatk_variant_recalibration_for_indels_gatk3 [Recalibrates INDEL calls using GATK VariantRecalibrator, gatk version >= 3.4-46]\n",
    "90. gatk_variant_recalibration_for_snps_gatk3 [Recalibrates SNP calls using GATK VariantRecalibrator, gatk version >= 3.4-46]\n",
    "91. genome_studio_import_from_irods [Import gtc files from iRODS along with metadata containing location of stored genome studio genotypes file. The metadata is used to obtain individual sample genotype files for genotype analysis.]\n",
    "92. import_bams [a pipeline for importing bams, getting their metadata]\n",
    "93. jws_test_malmods [test changed]\n",
    "94. jws_test_pipe [test]\n",
    "95. lane_bam_improvement [Improves bam files at lane-level by realigning around known indels, other clean ups ; adds the resulting bam to your VRTrack db]\n",
    "96. lane_bam_improvement_v2 [Improves bam files at lane-level by realigning around known indels, other clean ups ; adds the resulting bam to your VRTrack db. Differs from v1 in that it has additional bam_fix_bam after gatk indel realignments]\n",
    "97. linked_pipeline [a test pipeline for testing vrpipe sources]\n",
    "98. merge_candidate_list [Merges SNPs from VCFs creating a single output snp list.  Skips indels]\n",
    "99. merge_test_pipeline [a pipeline for testing bam merging]\n",
    "100. merge_vcf [Simple pipeline to merge multiple vcf into single vcf]\n",
    "101. merge_vcfs_to_site_list_and_recall_from_bcf [Create a merged site list from VCFs and recall at these sites from bcf.]\n",
    "102. mpileup_bcf [Run samtools mpileup to generate bcf files]\n",
    "103. penncnv_cnv_calling [Detect raw CNVs using PennCNV detect_cnv.pl, then filter using PennCNV filter_cnv.pl]\n",
    "104. pilon [Pilon variant calling and local assembly improvement]\n",
    "105. platypus_callvariants [Runs Platypus callvariants]\n",
    "106. pluritest_gene_expression_analysis [Reformat the Genome Studio csv files for gene expression data and run the R PluriTest analysis package to generate graphs and ancillary data]\n",
    "107. pysamstats_cov_mapq [Get coverage and mapq stats from bam for Panoptes]\n",
    "108. qa_stage_1_1 [runs qa stage 1_1]\n",
    "109. qa_stage_1_2 [runs qa stage 1_2]\n",
    "110. qa_stage_2 [runs qa steps 2]\n",
    "111. qa_stage_3 [runs qa stage 3]\n",
    "112. qa_stage_4 [runs qa stage 4]\n",
    "113. qa_stage_5 [runs qa stage 5]\n",
    "114. quantisnp_cnv_calling [Reformat genotyping data for use with QuantiSNP, then detect CNVs using Quantisnp]\n",
    "115. retroseq_analysis [Run retroseq genotyping of transposable elements from short read alignments]\n",
    "116. rna_seq_map_gsnap [RNA-Seq Mapping Pipeline employing GSNAP.]\n",
    "117. rna_seq_transcript_quantify_cufflinks [RNA-Seq transcript assembly and quantification pipeline employing Cufflinks.]\n",
    "118. sample_bam_improvement [Improves bam files at sample-level by realigning around known indels, creates summary of stats on bam files]\n",
    "119. samtools_bam_stats [Runs samtools stats, adds metada into bam file]\n",
    "120. samtools_bam_stats_gatk_callable_loci_gatk3 [Runs samtools bamstats and gatk callable loci, adds metada into bam file]\n",
    "121. sga_merge_and_variant_calling [Merge up to 16 fastq files and use sga to call variants: sga merge three times and sga graph-diff.]\n",
    "122. sga_prepare_fastq [Split BAMs by chromosome, converts to fastq and preprocesses with sga.]\n",
    "123. sga_prepare_many_region_fastq [Split BAMs by region, converts to fastq and preprocesses with sga.]\n",
    "124. sga_prepare_region_fastq [Split BAMs by region, converts to fastq and preprocesses with sga.]\n",
    "125. sga_variant_calling [Use sga to call variants. Merge and index fastq, sga index and sga graph-diff.]\n",
    "126. snp_calling_cortex [Calls variants using cortex BW assembler]\n",
    "127. snp_calling_gatk2_unified_genotyper [gatk best practices phase 2 pipeline, runs gatk unifiedgenotyper]\n",
    "128. snp_calling_gatk3_genotype_gvcfs [Runs gatk genotypegvcfs, also indexes vcf file,  gatk version >= 3.4-46]\n",
    "129. snp_calling_gatk3_haplotype_caller [gatk v3 best practices variant discovery pipeline, runs gatk haplotype caller]\n",
    "130. snp_calling_gatk3_haplotype_caller_v2 [Runs gatk haplotype caller, gatk version >= 3.4-46]\n",
    "131. snp_calling_gatk3_unified_genotyper [gatk best practices phase 2 pipeline, runs gatk unifiedgenotyper]\n",
    "132. snp_calling_gatk3_unified_genotyper_v2 [gatk best practices phase 2 pipeline, runs gatk unifiedgenotyper for version 3.4-46 or greater]\n",
    "133. snp_calling_gatk_haplotype_caller [Run GATK Haplotype Caller]\n",
    "134. snp_calling_gatk_unified_genotyper [Run gatk unified genotyper]\n",
    "135. snp_calling_gatk_unified_genotyper_and_annotate [Run gatk unified genotyper followed by vcf-annotate]\n",
    "136. snp_calling_gatk_unified_genotyper_and_filter_vcf [Call variants with the GATK universal genotyper, then hard-filter the results with GATK variant filtration]\n",
    "137. snp_calling_mpileup [Run samtools mpileup to generate vcf files]\n",
    "138. snp_calling_mpileup_from_bcf [Run bcftools to produce vcf from bcf files]\n",
    "139. snp_calling_mpileup_via_bcf [Run samtools mpileup generating both bcf and vcf files]\n",
    "140. speciator [Species detection via speciator]\n",
    "141. stringent_genotype_filter [Filter BAM files to SNP-o-matic]\n",
    "142. test_pipeline [a test pipeline for testing]\n",
    "143. upload_ega [Uploads files into the EGA dropbox using the EGA upload client application]\n",
    "144. variant_annotation_using_snpeff_gatk_vcf_annotate [variant annotation using snpeff,gatk and vcf_annotate tools]\n",
    "145. vcf_annotate [Annotate multiple vcfs using vcf-annotate]\n",
    "146. vcf_combine_genotypes_and_sites [Merge a sites only VCF file with the genotypes found in another VCF file(s), keeping the FILTER, ID and INFO fields found in the sites only file]\n",
    "147. vcf_concat [Concatenate multiple vcfs using vcf-concat]\n",
    "148. vcf_fast_merge_prepared_multistage [Runs three iterations of the vcf_fast_merge_prepared step]\n",
    "149. vcf_filter_merge_and_vep_annotate [Filter then merge VCF files and then annotate them with consequences using VEP]\n",
    "150. vcf_generate_candidate_snp_list [Merges SNPs from VCFs creating a single output snp list.  Skips indels]\n",
    "151. vcf_merge [Merge multiple VCF files with vcf-isec]\n",
    "152. vcf_merge_prepared_multistage [Runs three iterations of the vcf_merge_prepared step]\n",
    "153. vcf_split_and_vep_annotate [Split VCF files into smaller chunks, run vcf consequence annotation using VEP and remerge annotated VCFs]\n",
    "154. vcf_statistics [runs single step pipeline to generate vcf stats]\n",
    "155. vcf_to_irods [Add vcf files with metadata to irods]\n",
    "156. vcf_vep_annotate [Annotate VCF files with consequences using VEP]\n",
    "157. verify_bamid [Run verifyBamID contamination check to verify genotype in bam files]\n",
    "158. vfp_stage0 [Run stage 0 of the variation filtering pipeline]\n",
    "159. vfp_stage1 [Run stage 1 of the variation filtering pipeline]\n",
    "160. vfp_stage1_v2 [Run stage 1 of the variation filtering pipeline]\n",
    "161. vfp_stage1_v3 [Run stage 1 of the variation filtering pipeline]\n",
    "162. vfp_stage1_v4 [Run stage 1 of the variation filtering pipeline; used for Pf release 4.0]\n",
    "163. vfp_stage2 [Run stage 2 of the variation filtering pipeline]\n",
    "164. vfp_stage2_v2 [Run stage 2 of the variation filtering pipeline]\n",
    "165. vfp_stage3 [Run stage 3 of the variation filtering pipeline]\n",
    "166. vfp_stage3_v2 [Run stage 3 of the variation filtering pipeline]\n",
    "167. vfp_stage4 [Run stage 4 of the variation filtering pipeline]\n",
    "168. vqsr [Filter VCFs with VQSR.]\n",
    "169. vqsr_for_snps [Filter SNPs with VQSR.]\n",
    "170. vqsr_for_snps_and_indels [Run VQSR on SNPs and indels.]\n",
    "171. vrtrack_auto_qc [Considering the stats in the bamcheck file for a lane, and the metadata stored on the bam file and in the VRTrack database for the corresponding lane, automatically decide if the lane passes the quality check.]\n",
    "172. vrtrack_inject_qcstatus [For a set of bam files already in vr-pipe, extract the qc_status from vrtrack and add it to the metadata on the bam in vr-pipe.]\n",
    "173. vrtrack_qc [Generate QC stats and graphs and update the VRTrack db.]\n",
    "174. vrtrack_qc_graphs_and_auto_qc [Given bam files already on disc, generate QC stats and graphs, do the auto-qc anaylsis on the results, and update the VRTrack db.]\n",
    "175. vrtrack_update_mapstats_hipsci [Pipeline to update vrtrack mapstats for hipsci genotyping post CNV calling]\n",
    "Pick a pipeline from the above list to run <1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|100|101|102|103|104|105|106|107|108|109|110|111|112|113|114|115|116|117|118|119|120|121|122|123|124|125|126|127|128|129|130|131|132|133|134|135|136|137|138|139|140|141|142|143|144|145|146|147|148|149|150|151|152|153|154|155|156|157|158|159|160|161|162|163|164|165|166|167|168|169|170|171|172|173|174|175>: 78\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_combine_gvcfs_gatk3_merge_prepared - Run GATK CombineGVCFs on gvcfs, also indexes vcf file, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (1 or more gvcf files for merging)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10>: 8\n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source: WillH_haplotype_caller[gatk_haplotype_caller_gatk3_v2:gatk_vcf_file]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3>: 1\n",
    "\n",
    "Please provide your options to the 'group_by_metadata' method:\n",
    "\tmetadata_keys (REQUIRED, a Str): chrom\n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'gatk_combine_gvcfs_gatk3_merge_prepared' pipeline:\n",
    "\ttmp_dir (optional, used by step gatk_combine_gvcfs_gatk3_merge_prepared)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tmaxDirectMergingGroup (optional, used by step gatk_combine_gvcfs_gatk3_merge_prepared)\n",
    "\tmaximum number of gVCF files to merge simultaneously [50]: 100\n",
    "\tjava_exe (optional, used by step gatk_combine_gvcfs_gatk3_merge_prepared)\n",
    "\tpath to your java executable [java]: /software/jre1.7.0_25/bin/java\n",
    "\tcombine_gvcfs_options (optional, used by step gatk_combine_gvcfs_gatk3_merge_prepared)\n",
    "\tOptions for GATK CombineGVCFs, excluding -R,-variant,-o: \n",
    "\tminimum_records (optional, used by step gatk_combine_gvcfs_gatk3_merge_prepared)\n",
    "\tMinimum number of records expected in output VCF. Not recommended if using genome chunking [0]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_combine_gvcfs_gatk3_merge_prepared)\n",
    "\tpath to GATK v3 jar files: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by step gatk_combine_gvcfs_gatk3_merge_prepared)\n",
    "\tabsolute path to genome reference file used to do the mapping: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_key (REQUIRED, used by step gatk_combine_gvcfs_gatk3_merge_prepared)\n",
    "\tpath to GATK v3 key file: /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'remove_input_vcfs' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server): team112\n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <random|farm3> [random]: farm3\n",
    "What would you like to call your new pipeline setup?: WillH_combine_gvcfs\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_combine_gvcfs (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->group_by_metadata with source WillH_haplotype_caller[gatk_haplotype_caller_gatk3_v2:gatk_vcf_file]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmetadata_keys => chrom\n",
    "\tPipeline: gatk_combine_gvcfs_gatk3_merge_prepared (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\tmaxDirectMergingGroup => 100\n",
    "\t\tminimum_records => 0\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tremove_input_vcfs => 0\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_combine_gvcfs; Id: 738 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Genotype gvcfs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_2640_genotype_gvcfs\n",
    "Based on PipelineSetup 629, your new setup will use the pipeline 'snp_calling_gatk3_genotype_gvcfs'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_genotype_gvcfs_gatk3 - Run GATK GenotypeGVCFs on all gvcfs, also indexes vcf file, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (1 or more gvcf files for genotyping)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [4]: 8\n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source: WillH_combine_gvcfs[1:genomic_vcf_files]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3>: 1\n",
    "\n",
    "Please provide your options to the 'group_by_metadata' method:\n",
    "\tmetadata_keys (REQUIRED, a Str): chrom\n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'snp_calling_gatk3_genotype_gvcfs' pipeline:\n",
    "\ttmp_dir (optional, used by step gatk_genotype_gvcfs_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by step gatk_genotype_gvcfs_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgenotyper_options (REQUIRED, used by step gatk_genotype_gvcfs_gatk3)\n",
    "\tOptions for GATK GenotypeGVCFs, excluding -R,--variant,-o [--max_alternate_alleles 6 --annotation QualByDepth --annotation FisherStrand --annotation StrandOddsRatio --annotation VariantType --annotation GCContent --annotation TandemRepeatAnnotator]: \n",
    "\tminimum_records (optional, used by step gatk_genotype_gvcfs_gatk3)\n",
    "\tMinimum number of records expected in output VCF. Not recommended if using genome chunking [0]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_genotype_gvcfs_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by step gatk_genotype_gvcfs_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_key (REQUIRED, used by step gatk_genotype_gvcfs_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'remove_input_vcfs' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_genotype_gvcfs\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_genotype_gvcfs (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->group_by_metadata with source WillH_combine_gvcfs[1:genomic_vcf_files]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmetadata_keys => chrom\n",
    "\tPipeline: snp_calling_gatk3_genotype_gvcfs (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tgenotyper_options => --max_alternate_alleles 6 --annotation QualByDepth --annotation FisherStrand --annotation StrandOddsRatio --annotation VariantType --annotation GCContent --annotation TandemRepeatAnnotator\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\tminimum_records => 0\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tremove_input_vcfs => 0\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_genotype_gvcfs; Id: 739 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Variant recalibration SNPs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_2640_variant_recalibration_snps\n",
    "Based on PipelineSetup 630, your new setup will use the pipeline 'gatk_variant_recalibration_for_snps_gatk3'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_variant_recalibration_for_snps_gatk3 - Recalibrates SNP calls using GATK VariantRecalibrator, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (1 or more vcf files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_2640_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]]: WillH_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [2]: \n",
    "\n",
    "Please provide your options to the 'group_all' method:\n",
    "\tfilter (optional, a Str): \n",
    "\n",
    "Please provide options for the 'gatk_variant_recalibration_for_snps_gatk3' pipeline:\n",
    "\ttmp_dir (optional, used by step gatk_variant_recalibration_for_snps_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tsnp_variant_recalibration_options (optional, used by step gatk_variant_recalibration_for_snps_gatk3)\n",
    "\tCommand line options for GATK VariantRecalibrator when in SNP mode, excluding reference, mode, input, output files and VariantRecalibrator task command. Usually specifies a list of resources and annotations [-resource:7g8_gb4,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/7g8_gb4.combined.final.vcf.gz -resource:hb3_dd2,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/hb3_dd2.combined.final.vcf.gz -resource:3d7_hb3,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/3d7_hb3.combined.final.vcf.gz -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -an DP --maxGaussians 8]: -resource:7g8_gb4,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/7g8_gb4.combined.final.vcf.gz -resource:hb3_dd2,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/hb3_dd2.combined.final.vcf.gz -resource:3d7_hb3,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/3d7_hb3.combined.final.vcf.gz -an QD -an MQ -an FS -an SOR -an DP --maxGaussians 8 --MQCapForLogitJitterTransform 70    \n",
    "\tjava_exe (optional, used by step gatk_variant_recalibration_for_snps_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_variant_recalibration_for_snps_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by step gatk_variant_recalibration_for_snps_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_key (REQUIRED, used by step gatk_variant_recalibration_for_snps_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_variant_recalibration_snps\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_variant_recalibration_snps (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->group_all with source WillH_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]:\n",
    "\tPipeline: gatk_variant_recalibration_for_snps_gatk3 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tsnp_variant_recalibration_options => -resource:7g8_gb4,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/7g8_gb4.combined.final.vcf.gz -resource:hb3_dd2,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/hb3_dd2.combined.final.vcf.gz -resource:3d7_hb3,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/3d7_hb3.combined.final.vcf.gz -an QD -an MQ -an FS -an SOR -an DP --maxGaussians 8 --MQCapForLogitJitterTransform 70\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_variant_recalibration_snps; Id: 740 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Variant recalibration indels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_2640_variant_recalibration_indels\n",
    "Based on PipelineSetup 631, your new setup will use the pipeline 'gatk_variant_recalibration_for_indels_gatk3'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_variant_recalibration_for_indels_gatk3 - Recalibrates INDEL calls using GATK VariantRecalibrator, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (1 or more vcf files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_2640_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]]: WillH_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [2]: \n",
    "\n",
    "Please provide your options to the 'group_all' method:\n",
    "\tfilter (optional, a Str): \n",
    "\n",
    "Please provide options for the 'gatk_variant_recalibration_for_indels_gatk3' pipeline:\n",
    "\tindel_variant_recalibration_options (optional, used by step gatk_variant_recalibration_for_indels_gatk3)\n",
    "\tCommand line options for GATK VariantRecalibrator when in INDEL mode, excluding reference, mode, input, output files and VariantRecalibrator task command. Usually specifies a list of resources and annotations [-resource:7g8_gb4,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/7g8_gb4.combined.final.vcf.gz -resource:hb3_dd2,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/hb3_dd2.combined.final.vcf.gz -resource:3d7_hb3,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/3d7_hb3.combined.final.vcf.gz -an QD -an DP -an MQ -an FS -an BaseQRankSum --maxGaussians 4]: -resource:7g8_gb4,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/7g8_gb4.combined.final.vcf.gz -resource:hb3_dd2,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/hb3_dd2.combined.final.vcf.gz -resource:3d7_hb3,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/3d7_hb3.combined.final.vcf.gz -an QD -an FS -an SOR -an DP --maxGaussians 4 --MQCapForLogitJitterTransform 70\n",
    "\ttmp_dir (optional, used by step gatk_variant_recalibration_for_indels_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by step gatk_variant_recalibration_for_indels_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_variant_recalibration_for_indels_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by step gatk_variant_recalibration_for_indels_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_key (REQUIRED, used by step gatk_variant_recalibration_for_indels_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_variant_recalibration_indels\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_variant_recalibration_indels (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->group_all with source WillH_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]:\n",
    "\tPipeline: gatk_variant_recalibration_for_indels_gatk3 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tindel_variant_recalibration_options => -resource:7g8_gb4,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/7g8_gb4.combined.final.vcf.gz -resource:hb3_dd2,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/hb3_dd2.combined.final.vcf.gz -resource:3d7_hb3,known=false,training=true,truth=true,prior=15.0 /nfs/team112_internal/oxford_mirror/data/plasmodium/pfalciparum/pf-crosses/data/public/1.0/3d7_hb3.combined.final.vcf.gz -an QD -an FS -an SOR -an DP --maxGaussians 4 --MQCapForLogitJitterTransform 70\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_variant_recalibration_indels; Id: 741 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Apply recalibration SNPs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_2640_select_variants_apply_recalibration_snps\n",
    "Based on PipelineSetup 632, your new setup will use the pipeline 'gatk_select_variants_apply_recalibration_for_snps_gatk3'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_select_variants_gatk3 - Runs gatk SelectVariants, also indexes vcf, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (1 or more vcf files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_2640_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]]: WillH_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [3]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'gatk_select_variants_apply_recalibration_for_snps_gatk3' pipeline:\n",
    "\ttmp_dir (optional, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_snps_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_snps_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgatk_path (REQUIRED, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_snps_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_snps_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_select_variants_options (optional, used by step gatk_select_variants_gatk3)\n",
    "\tcommand line options for GATK SelectVariants; excludes reference, input, output files and SelectVariants task command [-selectType SNP]: \n",
    "\tgatk_key (REQUIRED, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_snps_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\tsnp_apply_recalibraton_options (optional, used by step gatk_apply_recalibration_for_snps_gatk3)\n",
    "\tCommand line options for GATK ApplyRecalibration when in SNP mode, excluding reference, mode, input, output files and ApplyRecalibration task command [--ts_filter_level 99.5 -tranchesFile /lustre/scratch109/malaria/pf3k_methods/output/0/9/3/f/394666/1_gatk_variant_recalibration_for_snps_gatk3/SNP.recal.tranches -recalFile /lustre/scratch109/malaria/pf3k_methods/output/0/9/3/f/394666/1_gatk_variant_recalibration_for_snps_gatk3/SNP.recal]: --ts_filter_level 99.5 -tranchesFile /lustre/scratch109/malaria/WillH_1/output/3/b/2/d/600989/1_gatk_variant_recalibration_for_snps_gatk3/SNP.recal.tranches -recalFile /lustre/scratch109/malaria/WillH_1/output/3/b/2/d/600989/1_gatk_variant_recalibration_for_snps_gatk3/SNP.recal\n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 1\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "\t'remove_input_vcfs' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_select_variants_apply_recalibration_snps\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_select_variants_apply_recalibration_snps (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: gatk_select_variants_apply_recalibration_for_snps_gatk3 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tcleanup => 0\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tgatk_select_variants_options => -selectType SNP\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tremove_input_vcfs => 0\n",
    "\t\tsnp_apply_recalibraton_options => --ts_filter_level 99.5 -tranchesFile /lustre/scratch109/malaria/WillH_1/output/3/b/2/d/600989/1_gatk_variant_recalibration_for_snps_gatk3/SNP.recal.tranches -recalFile /lustre/scratch109/malaria/WillH_1/output/3/b/2/d/600989/1_gatk_variant_recalibration_for_snps_gatk3/SNP.recal\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_select_variants_apply_recalibration_snps; Id: 742 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Apply recalibration indels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_2640_select_variants_apply_recalibration_indels\n",
    "Based on PipelineSetup 633, your new setup will use the pipeline 'gatk_select_variants_apply_recalibration_for_indels_gatk3'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_select_variants_gatk3 - Runs gatk SelectVariants, also indexes vcf, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (1 or more vcf files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_2640_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]]: WillH_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [3]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'gatk_select_variants_apply_recalibration_for_indels_gatk3' pipeline:\n",
    "\ttmp_dir (optional, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_indels_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_indels_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgatk_path (REQUIRED, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_indels_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_indels_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_select_variants_options (optional, used by step gatk_select_variants_gatk3)\n",
    "\tcommand line options for GATK SelectVariants; excludes reference, input, output files and SelectVariants task command [-xlSelectType SNP]: \n",
    "\tgatk_key (REQUIRED, used by steps gatk_select_variants_gatk3, gatk_apply_recalibration_for_indels_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\tindel_apply_recalibraton_options (optional, used by step gatk_apply_recalibration_for_indels_gatk3)\n",
    "\tCommand line options for GATK ApplyRecalibration when in INDEL mode, excluding reference, mode, input, output files and ApplyRecalibration task command [--ts_filter_level 99.0 -tranchesFile /lustre/scratch109/malaria/pf3k_methods/output/d/7/8/5/394666/1_gatk_variant_recalibration_for_indels_gatk3/INDEL.recal.tranches -recalFile /lustre/scratch109/malaria/pf3k_methods/output/d/7/8/5/394666/1_gatk_variant_recalibration_for_indels_gatk3/INDEL.recal]: --ts_filter_level 99.0 -tranchesFile /lustre/scratch109/malaria/WillH_1/output/7/7/2/9/600989/1_gatk_variant_recalibration_for_indels_gatk3/INDEL.recal.tranches -recalFile /lustre/scratch109/malaria/WillH_1/output/7/7/2/9/600989/1_gatk_variant_recalibration_for_indels_gatk3/INDEL.recal\n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 1\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "\t'remove_input_vcfs' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_select_variants_apply_recalibration_indels\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_select_variants_apply_recalibration_indels (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_genotype_gvcfs[gatk_genotype_gvcfs_gatk3:gatk_vcf_file]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: gatk_select_variants_apply_recalibration_for_indels_gatk3 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tcleanup => 0\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tgatk_select_variants_options => -xlSelectType SNP\n",
    "\t\tindel_apply_recalibraton_options => --ts_filter_level 99.0 -tranchesFile /lustre/scratch109/malaria/WillH_1/output/7/7/2/9/600989/1_gatk_variant_recalibration_for_indels_gatk3/INDEL.recal.tranches -recalFile /lustre/scratch109/malaria/WillH_1/output/7/7/2/9/600989/1_gatk_variant_recalibration_for_indels_gatk3/INDEL.recal\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tremove_input_vcfs => 0\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_select_variants_apply_recalibration_indels; Id: 743 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Annotation SNPs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_2640_variant_annotation_using_snpeff_gatk_vcf_annotate_snps\n",
    "Based on PipelineSetup 634, your new setup will use the pipeline 'variant_annotation_using_snpeff_gatk_vcf_annotate'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (variant_annotation_using_snpeff - Annotates vcf files using snpEff toolkit, version > 4.1), which expects:\n",
    "\t\tFile type = vcf (1 or more vcf files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\t3 (gatk_variant_annotator_gatk3 - Executes GATK VariantAnnotator v3, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (one or more vcf files to be annotated)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_2640_select_variants_apply_recalibration_snps[gatk_apply_recalibration_for_snps_gatk3:recalibrated_vcf_files]]: WillH_select_variants_apply_recalibration_snps[gatk_apply_recalibration_for_snps_gatk3:recalibrated_vcf_files]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [3]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'variant_annotation_using_snpeff_gatk_vcf_annotate' pipeline:\n",
    "\ttmp_dir (optional, used by steps variant_annotation_using_snpeff, gatk_variant_annotator_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by steps variant_annotation_using_snpeff, gatk_variant_annotator_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tsnpeff_output_format (optional, used by step variant_annotation_using_snpeff)\n",
    "\tcommand line options -o ouput format [ either vcf or gatk ] [gatk]: \n",
    "\tsnpeff_options (optional, used by step variant_annotation_using_snpeff)\n",
    "\tcommand line options for snpEff; excludes -c, -dataDir, -q, -v, -noLog, -i, -o, input, output files and eff|ann task command [-no-downstream -no-upstream -onlyProtein]: \n",
    "\tsnpeff_config_path (REQUIRED, used by step variant_annotation_using_snpeff)\n",
    "\tabsolute path to snpeff configuration file [/lustre/scratch109/malaria/pf3k_methods/resources/snpEff/snpEff.config]: \n",
    "\tsnpeff_path (REQUIRED, used by step variant_annotation_using_snpeff)\n",
    "\tpath to snpeff v2 jar files [/nfs/team112_internal/production/tools/bin/snpEff_4_1/]: \n",
    "\tsnpeff_datadir_path (REQUIRED, used by step variant_annotation_using_snpeff)\n",
    "\tabsolute path to snpeff data directory -dataDir, this will be used to override data_dir value in config file [/lustre/scratch109/malaria/pf3k_methods/resources/snpEff/data/]: \n",
    "\tsnpeff_genome_version (REQUIRED, used by step variant_annotation_using_snpeff)\n",
    "\tsnpEff genome version, makse sure to build the database before using) [Pfalciparum_GeneDB_Aug2015]: \n",
    "\ttabix_exe (optional, used by steps vcf_index, vcf_index)\n",
    "\tpath to tabix executable [/usr/bin/tabix]: \n",
    "\tvariant_annotator_options (REQUIRED, used by step gatk_variant_annotator_gatk3)\n",
    "\tOptions for GATK VariantAnnotator, excluding --variant|-V|--snpEffFile|-I|-T options. [-A SnpEff]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_variant_annotator_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by step gatk_variant_annotator_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_key (REQUIRED, used by step gatk_variant_annotator_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\tvcf-annotate_exe (optional, used by step vcf_annotate)\n",
    "\tpath to your vcf-annotate executable [/nfs/team112_internal/production/tools/bin/vcftools_0.1.10/bin/vcf-annotate]: \n",
    "\tvcf-annotate_2_options (optional, used by step vcf_annotate)\n",
    "\tvcf-annotate pass 2 options: \n",
    "\tvcf-annotate_options (REQUIRED, used by step vcf_annotate)\n",
    "\tvcf-annotate pass 1 options [-a /nfs/users/nfs_r/rp7/src/github/malariagen/pf-crosses/meta/regions-20130225.bed.gz -d key=INFO,ID=RegionType,Number=1,Type=String,Description='The type of genome region within which the variant is found. SubtelomericRepeat: repetitive regions at the ends of the chromosomes. SubtelomericHypervariable: subtelomeric region of poor conservation between the 3D7 reference genome and other samples. InternalHypervariable: chromosome-internal region of poor conservation between the 3D7 reference genome and other samples. Centromere: start and end coordinates of the centromere genome annotation. Core: everything else.' -c CHROM,FROM,TO,INFO/RegionType]: -a /nfs/team112_internal/rp7/src/github/malariagen/pf-crosses/meta/regions-20130225.bed.gz -d key=INFO,ID=RegionType,Number=1,Type=String,Description='The type of genome region within which the variant is found. SubtelomericRepeat: repetitive regions at the ends of the chromosomes. SubtelomericHypervariable: subtelomeric region of poor conservation between the 3D7 reference genome and other samples. InternalHypervariable: chromosome-internal region of poor conservation between the 3D7 reference genome and other samples. Centromere: start and end coordinates of the centromere genome annotation. Core: everything else.' -c CHROM,FROM,TO,INFO/RegionType\n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 1, 2, 3\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "\t'remove_input_vcfs' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_snps\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_snps (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_select_variants_apply_recalibration_snps[gatk_apply_recalibration_for_snps_gatk3:recalibrated_vcf_files]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: variant_annotation_using_snpeff_gatk_vcf_annotate (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tcleanup => 0\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tremove_input_vcfs => 0\n",
    "\t\tsnpeff_config_path => /lustre/scratch109/malaria/pf3k_methods/resources/snpEff/snpEff.config\n",
    "\t\tsnpeff_datadir_path => /lustre/scratch109/malaria/pf3k_methods/resources/snpEff/data/\n",
    "\t\tsnpeff_genome_version => Pfalciparum_GeneDB_Aug2015\n",
    "\t\tsnpeff_options => -no-downstream -no-upstream -onlyProtein\n",
    "\t\tsnpeff_output_format => gatk\n",
    "\t\tsnpeff_path => /nfs/team112_internal/production/tools/bin/snpEff_4_1/\n",
    "\t\ttabix_exe => /usr/bin/tabix\n",
    "\t\tvariant_annotator_options => -A SnpEff\n",
    "\t\tvcf-annotate_exe => /nfs/team112_internal/production/tools/bin/vcftools_0.1.10/bin/vcf-annotate\n",
    "\t\tvcf-annotate_options => -a /nfs/team112_internal/rp7/src/github/malariagen/pf-crosses/meta/regions-20130225.bed.gz -d key=INFO,ID=RegionType,Number=1,Type=String,Description='The type of genome region within which the variant is found. SubtelomericRepeat: repetitive regions at the ends of the chromosomes. SubtelomericHypervariable: subtelomeric region of poor conservation between the 3D7 reference genome and other samples. InternalHypervariable: chromosome-internal region of poor conservation between the 3D7 reference genome and other samples. Centromere: start and end coordinates of the centromere genome annotation. Core: everything else.' -c CHROM,FROM,TO,INFO/RegionType\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_snps; Id: 744 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Annotation indels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_2640_variant_annotation_using_snpeff_gatk_vcf_annotate_indels\n",
    "Based on PipelineSetup 635, your new setup will use the pipeline 'variant_annotation_using_snpeff_gatk_vcf_annotate'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (variant_annotation_using_snpeff - Annotates vcf files using snpEff toolkit, version > 4.1), which expects:\n",
    "\t\tFile type = vcf (1 or more vcf files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\t3 (gatk_variant_annotator_gatk3 - Executes GATK VariantAnnotator v3, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (one or more vcf files to be annotated)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_2640_select_variants_apply_recalibration_indels[gatk_apply_recalibration_for_indels_gatk3:recalibrated_vcf_files]]: WillH_select_variants_apply_recalibration_indels[gatk_apply_recalibration_for_indels_gatk3:recalibrated_vcf_files]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [3]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'variant_annotation_using_snpeff_gatk_vcf_annotate' pipeline:\n",
    "\ttmp_dir (optional, used by steps variant_annotation_using_snpeff, gatk_variant_annotator_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by steps variant_annotation_using_snpeff, gatk_variant_annotator_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tsnpeff_output_format (optional, used by step variant_annotation_using_snpeff)\n",
    "\tcommand line options -o ouput format [ either vcf or gatk ] [gatk]: \n",
    "\tsnpeff_options (optional, used by step variant_annotation_using_snpeff)\n",
    "\tcommand line options for snpEff; excludes -c, -dataDir, -q, -v, -noLog, -i, -o, input, output files and eff|ann task command [-no-downstream -no-upstream -onlyProtein]: \n",
    "\tsnpeff_config_path (REQUIRED, used by step variant_annotation_using_snpeff)\n",
    "\tabsolute path to snpeff configuration file [/lustre/scratch109/malaria/pf3k_methods/resources/snpEff/snpEff.config]: \n",
    "\tsnpeff_path (REQUIRED, used by step variant_annotation_using_snpeff)\n",
    "\tpath to snpeff v2 jar files [/nfs/team112_internal/production/tools/bin/snpEff_4_1/]: \n",
    "\tsnpeff_datadir_path (REQUIRED, used by step variant_annotation_using_snpeff)\n",
    "\tabsolute path to snpeff data directory -dataDir, this will be used to override data_dir value in config file [/lustre/scratch109/malaria/pf3k_methods/resources/snpEff/data/]: \n",
    "\tsnpeff_genome_version (REQUIRED, used by step variant_annotation_using_snpeff)\n",
    "\tsnpEff genome version, makse sure to build the database before using) [Pfalciparum_GeneDB_Aug2015]: \n",
    "\ttabix_exe (optional, used by steps vcf_index, vcf_index)\n",
    "\tpath to tabix executable [/usr/bin/tabix]: \n",
    "\tvariant_annotator_options (REQUIRED, used by step gatk_variant_annotator_gatk3)\n",
    "\tOptions for GATK VariantAnnotator, excluding --variant|-V|--snpEffFile|-I|-T options. [-A SnpEff]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_variant_annotator_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by step gatk_variant_annotator_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_key (REQUIRED, used by step gatk_variant_annotator_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\tvcf-annotate_exe (optional, used by step vcf_annotate)\n",
    "\tpath to your vcf-annotate executable [/nfs/team112_internal/production/tools/bin/vcftools_0.1.10/bin/vcf-annotate]: \n",
    "\tvcf-annotate_2_options (optional, used by step vcf_annotate)\n",
    "\tvcf-annotate pass 2 options: \n",
    "\tvcf-annotate_options (REQUIRED, used by step vcf_annotate)\n",
    "\tvcf-annotate pass 1 options [-a /nfs/users/nfs_r/rp7/src/github/malariagen/pf-crosses/meta/regions-20130225.bed.gz -d key=INFO,ID=RegionType,Number=1,Type=String,Description='The type of genome region within which the variant is found. SubtelomericRepeat: repetitive regions at the ends of the chromosomes. SubtelomericHypervariable: subtelomeric region of poor conservation between the 3D7 reference genome and other samples. InternalHypervariable: chromosome-internal region of poor conservation between the 3D7 reference genome and other samples. Centromere: start and end coordinates of the centromere genome annotation. Core: everything else.' -c CHROM,FROM,TO,INFO/RegionType]: -a /nfs/team112_internal/rp7/src/github/malariagen/pf-crosses/meta/regions-20130225.bed.gz -d key=INFO,ID=RegionType,Number=1,Type=String,Description='The type of genome region within which the variant is found. SubtelomericRepeat: repetitive regions at the ends of the chromosomes. SubtelomericHypervariable: subtelomeric region of poor conservation between the 3D7 reference genome and other samples. InternalHypervariable: chromosome-internal region of poor conservation between the 3D7 reference genome and other samples. Centromere: start and end coordinates of the centromere genome annotation. Core: everything else.' -c CHROM,FROM,TO,INFO/RegionType\n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'cleanup' key controls the behaviours:\n",
    "\t\t'delete_outputs' - acts on steps 1, 2, 3\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "\t'remove_input_vcfs' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_indels\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_indels (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_select_variants_apply_recalibration_indels[gatk_apply_recalibration_for_indels_gatk3:recalibrated_vcf_files]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: variant_annotation_using_snpeff_gatk_vcf_annotate (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tcleanup => 0\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tremove_input_vcfs => 0\n",
    "\t\tsnpeff_config_path => /lustre/scratch109/malaria/pf3k_methods/resources/snpEff/snpEff.config\n",
    "\t\tsnpeff_datadir_path => /lustre/scratch109/malaria/pf3k_methods/resources/snpEff/data/\n",
    "\t\tsnpeff_genome_version => Pfalciparum_GeneDB_Aug2015\n",
    "\t\tsnpeff_options => -no-downstream -no-upstream -onlyProtein\n",
    "\t\tsnpeff_output_format => gatk\n",
    "\t\tsnpeff_path => /nfs/team112_internal/production/tools/bin/snpEff_4_1/\n",
    "\t\ttabix_exe => /usr/bin/tabix\n",
    "\t\tvariant_annotator_options => -A SnpEff\n",
    "\t\tvcf-annotate_exe => /nfs/team112_internal/production/tools/bin/vcftools_0.1.10/bin/vcf-annotate\n",
    "\t\tvcf-annotate_options => -a /nfs/team112_internal/rp7/src/github/malariagen/pf-crosses/meta/regions-20130225.bed.gz -d key=INFO,ID=RegionType,Number=1,Type=String,Description='The type of genome region within which the variant is found. SubtelomericRepeat: repetitive regions at the ends of the chromosomes. SubtelomericHypervariable: subtelomeric region of poor conservation between the 3D7 reference genome and other samples. InternalHypervariable: chromosome-internal region of poor conservation between the 3D7 reference genome and other samples. Centromere: start and end coordinates of the centromere genome annotation. Core: everything else.' -c CHROM,FROM,TO,INFO/RegionType\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_indels; Id: 745 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Combine SNPs and indels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_2640_combine_variants\n",
    "Based on PipelineSetup 636, your new setup will use the pipeline 'gatk_combine_variants_gatk3'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_combine_variants_gatk3 - Combines 2 vcf files, one each for SNP and INDEL, both with having metadata value for variation_mode and chrom, using GATK CombineVariants v3, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (2 vcf files, one each for SNP and INDEL, both with having metadata value for variation_mode and chrom)\n",
    "\t\tNumber of files = 2..2 (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [634[vcf_annotate:annotated_vcf]|635[vcf_annotate:annotated_vcf]]: WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_snps[vcf_annotate:annotated_vcf]|WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_indels[vcf_annotate:annotated_vcf]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [1]: \n",
    "\n",
    "Please provide your options to the 'group_by_metadata' method:\n",
    "\tmetadata_keys (REQUIRED, a Str) [chrom]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'gatk_combine_variants_gatk3' pipeline:\n",
    "\ttmp_dir (optional, used by step gatk_combine_variants_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tgatk_combine_variants_options (REQUIRED, used by step gatk_combine_variants_gatk3)\n",
    "\toptions for GATK CombineVariants, excluding reference genome, input and output files. [-genotypeMergeOptions PRIORITIZE -priority snp,indel]: \n",
    "\tjava_exe (optional, used by step gatk_combine_variants_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_combine_variants_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by step gatk_combine_variants_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_key (REQUIRED, used by step gatk_combine_variants_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'remove_input_vcfs' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_combine_variants\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_combine_variants (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->group_by_metadata with source WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_snps[vcf_annotate:annotated_vcf]|WillH_variant_annotation_using_snpeff_gatk_vcf_annotate_indels[vcf_annotate:annotated_vcf]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmetadata_keys => chrom\n",
    "\tPipeline: gatk_combine_variants_gatk3 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tgatk_combine_variants_options => -genotypeMergeOptions PRIORITIZE -priority snp,indel\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tremove_input_vcfs => 0\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_combine_variants; Id: 746 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Filter variants"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vrpipe-setup --based_on pf3kgatk_2640_variant_filtration\n",
    "Based on PipelineSetup 637, your new setup will use the pipeline 'gatk_variant_filter_gatk3'\n",
    "Your chosen pipeline takes DataSource input during step(s):\n",
    "\t1 (gatk_variant_filter_gatk3 - Runs gatk VariantFiltration, also indexes vcf, gatk version >= 3.4-46), which expects:\n",
    "\t\tFile type = vcf (1 or more vcf files)\n",
    "\t\tNumber of files = 1..unlimited (and they must exist)\n",
    "\n",
    "1. delimited (Use information in a delimited text file.)\n",
    "2. fofn (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "3. fofn_with_genome_chunking (Use a simple list of absolute file paths (file-of-file-names) in a file as your source.)\n",
    "4. fofn_with_metadata (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "5. fofn_with_metadata_with_genome_chunking (Use information in a tab-delimited text file which specifies file paths and metadata to apply to that file.)\n",
    "6. list (Use a simple list of items in a file as your source.)\n",
    "7. sequence_index (Use fastq files specified in a DCC sequence.index file, associating all the metadata available)\n",
    "8. vrpipe (Use files created by VRPipe pipelines as a datasource.)\n",
    "9. vrpipe_with_genome_chunking (Use files created by VRPipe pipelines as a datasource.)\n",
    "10. vrtrack (Use a VRTrack database to extract information from)\n",
    "Pick a DataSource type from the above list <1|2|3|4|5|6|7|8|9|10> [8]: \n",
    "vrpipe DataSources have a source described as:\n",
    "List of pipelinesetup names or ids separated by a pipe character '|'. Each pipeline setup or id may be followed in square brackets by the step number or step name which produced the output files to be used. Optionally, if a step produced multiple types of output files, the step name or number may be followed by the output file key to identify the correct files to be used. Multiple steps from the same pipeline setup may be specified. e.g. pipeline_setup_id[step_name:output_file_key]|pipeline_setup_name[step_number1,step_number2]'\n",
    "Supply the source [pf3kgatk_2640_combine_variants[gatk_combine_variants_gatk3:combined_vcf_files]]: WillH_combine_variants[gatk_combine_variants_gatk3:combined_vcf_files]\n",
    "\n",
    "1. group_by_metadata (Files from the source will be grouped according to their metadata keys. Requires the metadata_keys option which is a '|' separated list of metadata keys by which dataelements will be grouped. e.g. metadata_keys => 'sample|platform|library' will groups all elements with the same sample, platform and library into one dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "2. group_all (All output files in the vrpipe datasource will be grouped into a single element. The filter option is a string of the form 'metadata_key#regex' which will select only files with metadata matching the regex; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas).)\n",
    "3. all (Each element will consist of the output files from the vrpipe datasource. If the maintain_element_grouping option is set to 1 (default), then all files produced by a dataelement in the source will be grouped into a dataelement. Otherwise, each source file will be it's own dataelement. The filter option is a string of the form 'metadata_key#regex'; multiple filters can be separated by commas (and neither the keys nor regexs can include hashes or commas). If the filter_after_grouping option is set (the default), grouping based on metadata will be performed first and then the filter applied with it only being necessary for one file in the group to pass the filter by having metadata matching the regex. If the filter_after_grouping option is not set, only files which match the regex will be included and grouped based on their metadata.)\n",
    "Pick one of the vrpipe DataSource methods from the above list <1|2|3> [3]: \n",
    "\n",
    "Please provide your options to the 'all' method:\n",
    "\tmaintain_element_grouping (optional, a Bool) [1]: \n",
    "\tfilter (optional, a Str): \n",
    "\tfilter_after_grouping (optional, a Bool) [1]: \n",
    "\n",
    "Please provide options for the 'gatk_variant_filter_gatk3' pipeline:\n",
    "\ttmp_dir (optional, used by step gatk_variant_filter_gatk3)\n",
    "\tlocation for tmp directories; defaults to working directory: \n",
    "\tjava_exe (optional, used by step gatk_variant_filter_gatk3)\n",
    "\tpath to your java executable [/software/jre1.7.0_25/bin/java]: \n",
    "\tgatk_path (REQUIRED, used by step gatk_variant_filter_gatk3)\n",
    "\tpath to GATK v3 jar files [/nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.4-46]: /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\treference_fasta (REQUIRED, used by step gatk_variant_filter_gatk3)\n",
    "\tabsolute path to genome reference file used to do the mapping [/lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta]: /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\tgatk_key (REQUIRED, used by step gatk_variant_filter_gatk3)\n",
    "\tpath to GATK v3 key file [/nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key]: \n",
    "\tgatk_variant_filtration_options (optional, used by step gatk_variant_filter_gatk3)\n",
    "\tcommand line options for GATK VariantFiltration; excludes reference, input, output files and VariantFiltration task command [--filterName \\\"Low_VQSLOD\\\" --filterExpression \\\"VQSLOD <= 0.0\\\" --filterName \\\"Centromere\\\" --filterExpression \\\"RegionType == 'Centromere'\\\" --filterName \\\"InternalHypervariable\\\" --filterExpression \\\"RegionType == 'InternalHypervariable'\\\" --filterName \\\"SubtelomericHypervariable\\\" --filterExpression \\\"RegionType == 'SubtelomericHypervariable'\\\" --filterName \\\"SubtelomericRepeat\\\" --filterExpression \\\"RegionType == 'SubtelomericRepeat'\\\" --invalidatePreviousFilters]: \n",
    "\n",
    "Certain behaviours of your pipeline are regulated by boolean keys:\n",
    "\t'remove_input_vcfs' key controls the behaviours:\n",
    "\t\t'delete_inputs' - acts on steps 0\n",
    "\tTurn this behaviour on (1) or off (0)? <0|1> [0]: \n",
    "Please provide the absolute path to the root directory that output files will be written to [/lustre/scratch109/malaria/pf3k_methods/output]: /lustre/scratch109/malaria/WillH_1/output\n",
    "Which Unix group should output files should belong to (no answer uses the default group of the user that runs vrpipe-server) [team112]: \n",
    "Which vrpipe-server (identified by the 'farm' name) should the setup be controlled by (entering nothing means a random server will be used) <farm3> [farm3]: \n",
    "What would you like to call your new pipeline setup?: WillH_variant_filtration\n",
    "\n",
    "We've now gathered all information; here's what you've asked for:\n",
    "\tPipelineSetup name: WillH_variant_filtration (for user rp7 controlled by farm 'farm3')\n",
    "\tDataSource: vrpipe->all with source WillH_combine_variants[gatk_combine_variants_gatk3:combined_vcf_files]:\n",
    "\t\tfilter_after_grouping => 1\n",
    "\t\tmaintain_element_grouping => 1\n",
    "\tPipeline: gatk_variant_filter_gatk3 (outputting to /lustre/scratch109/malaria/WillH_1/output belonging to group team112):\n",
    "\t\tgatk_key => /nfs/team112_internal/production/tools/bin/gatk/dj6_sanger.ac.uk.key\n",
    "\t\tgatk_path => /nfs/team112_internal/production/tools/bin/gatk/GenomeAnalysisTK-3.5\n",
    "\t\tgatk_variant_filtration_options => --filterName \\\"Low_VQSLOD\\\" --filterExpression \\\"VQSLOD <= 0.0\\\" --filterName \\\"Centromere\\\" --filterExpression \\\"RegionType == 'Centromere'\\\" --filterName \\\"InternalHypervariable\\\" --filterExpression \\\"RegionType == 'InternalHypervariable'\\\" --filterName \\\"SubtelomericHypervariable\\\" --filterExpression \\\"RegionType == 'SubtelomericHypervariable'\\\" --filterName \\\"SubtelomericRepeat\\\" --filterExpression \\\"RegionType == 'SubtelomericRepeat'\\\" --invalidatePreviousFilters\n",
    "\t\tjava_exe => /software/jre1.7.0_25/bin/java\n",
    "\t\treference_fasta => /lustre/scratch109/malaria/pf3k_methods/resources/Pfalciparum.genome.fasta\n",
    "\t\tremove_input_vcfs => 0\n",
    "Is all of this correct? <y|n>: y\n",
    "\n",
    "Your new PipelineSetup has been created!\n",
    "Name: WillH_variant_filtration; Id: 747 (remember at least one of these for use later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Symlinks for VCFs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cd /nfs/team112_internal/production/release_build/Pf/WillH_1\n",
    "mkdir vcf_symlinks\n",
    "mkdir vcf\n",
    "vrpipe-output --setup WillH_variant_filtration --output_dir /nfs/team112_internal/production/release_build/Pf/WillH_1/vcf_symlinks --basename_as_output\n",
    "cp -L vcf_symlinks/* vcf/\n",
    "rm -R vcf_symlinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create whole genome vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reran this as below piping through sed command to fix AD in header\n",
    "# !{BCFTOOLS} concat --output {WG_VCF_FN} --output-type z {\" \".join(chromosome_vcfs)}\n",
    "# !tabix -p vcf {WG_VCF_FN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tabix] the index file exists. Please use '-f' to overwrite.\r\n"
     ]
    }
   ],
   "source": [
    "!{BCFTOOLS} concat {\" \".join(chromosome_vcfs)} \\\n",
    "| sed 's/##FORMAT=<ID=AD,Number=./##FORMAT=<ID=AD,Number=R/' \\\n",
    "| bgzip -c > {WG_VCF_FN}\n",
    "!tabix -p vcf {WG_VCF_FN}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create bam summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!vrpipe-fileinfo \\\n",
    "--setup WillH_mergelibs \\\n",
    "--step 1 \\\n",
    "--metadata sample,study,bases_callable_percent,bases_no_coverage_percent,bases_low_coverage_percent,bases_poor_mapping_quality_percent,mean_coverage \\\n",
    "> {RELEASE_METADATA_FN}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create README section containing variant numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583,970 variants\n",
      "346,940 SNPs\n",
      "237,030 indels\n",
      "\n",
      "156,912 PASS variants\n",
      "57,728 PASS SNPs\n",
      "99,184 PASS indels\n",
      "\n",
      "90,361 PASS biallelic variants\n",
      "50,142 PASS biallelic SNPs\n",
      "40,219 PASS biallelic indels\n",
      "\n",
      "66,057 VQSLOD>6.0 variants\n",
      "32,869 VQSLOD>6.0 SNPs\n",
      "33,188 VQSLOD>6.0 indels\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_snps = !{BCFTOOLS} query -f '%CHROM\\t%POS\\n' --include 'TYPE=\"snp\"' {WG_VCF_FN} | wc -l\n",
    "number_of_indels = !{BCFTOOLS} query -f '%CHROM\\t%POS\\n' --include 'TYPE!=\"snp\"' {WG_VCF_FN} | wc -l\n",
    "number_of_pass_snps = !{BCFTOOLS} query -f '%CHROM\\t%POS\\n' --include 'FILTER=\"PASS\" && TYPE=\"snp\"' {WG_VCF_FN} | wc -l\n",
    "number_of_pass_indels = !{BCFTOOLS} query -f '%CHROM\\t%POS\\n' --include 'FILTER=\"PASS\" && TYPE!=\"snp\"' {WG_VCF_FN} | wc -l\n",
    "number_of_pass_biallelic_snps = !{BCFTOOLS} query -f '%CHROM\\t%POS\\n' --include 'FILTER=\"PASS\" && TYPE=\"snp\" && N_ALT=1' {WG_VCF_FN} | wc -l\n",
    "number_of_pass_biallelic_indels = !{BCFTOOLS} query -f '%CHROM\\t%POS\\n' --include 'FILTER=\"PASS\" && TYPE!=\"snp\" && N_ALT=1' {WG_VCF_FN} | wc -l\n",
    "number_of_VQSLODgt6_snps = !{BCFTOOLS} query -f '%CHROM\\t%POS\\n' --include 'FILTER=\"PASS\" && TYPE=\"snp\" && VQSLOD>6' {WG_VCF_FN} | wc -l\n",
    "number_of_VQSLODgt6_indels = !{BCFTOOLS} query -f '%CHROM\\t%POS\\n' --include 'FILTER=\"PASS\" && TYPE!=\"snp\" && VQSLOD>6' {WG_VCF_FN} | wc -l\n",
    "\n",
    "print(\"%s variants\" % (\"{:,}\".format(int(number_of_snps[0]) + int(number_of_indels[0]))))\n",
    "print(\"%s SNPs\" % (\"{:,}\".format(int(number_of_snps[0]))))\n",
    "print(\"%s indels\" % (\"{:,}\".format(int(number_of_indels[0]))))\n",
    "print()\n",
    "print(\"%s PASS variants\" % (\"{:,}\".format(int(number_of_pass_snps[0]) + int(number_of_pass_indels[0]))))\n",
    "print(\"%s PASS SNPs\" % (\"{:,}\".format(int(number_of_pass_snps[0]))))\n",
    "print(\"%s PASS indels\" % (\"{:,}\".format(int(number_of_pass_indels[0]))))\n",
    "print()\n",
    "print(\"%s PASS biallelic variants\" % (\"{:,}\".format(int(number_of_pass_biallelic_snps[0]) + int(number_of_pass_biallelic_indels[0]))))\n",
    "print(\"%s PASS biallelic SNPs\" % (\"{:,}\".format(int(number_of_pass_biallelic_snps[0]))))\n",
    "print(\"%s PASS biallelic indels\" % (\"{:,}\".format(int(number_of_pass_biallelic_indels[0]))))\n",
    "print()\n",
    "print(\"%s VQSLOD>6.0 variants\" % (\"{:,}\".format(int(number_of_VQSLODgt6_snps[0]) + int(number_of_VQSLODgt6_indels[0]))))\n",
    "print(\"%s VQSLOD>6.0 SNPs\" % (\"{:,}\".format(int(number_of_VQSLODgt6_snps[0]))))\n",
    "print(\"%s VQSLOD>6.0 indels\" % (\"{:,}\".format(int(number_of_VQSLODgt6_indels[0]))))\n",
    "print()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The VCF file contains details of 583,970 discovered variants of which 346,940\n",
      "are SNPs and 237,030 are indels (or multi-allelic mixtures of SNPs\n",
      "and indels). It is important to note that many of these variants are\n",
      "considered low quality. Only the variants for which the FILTER column is set\n",
      "to PASS should be considered of high quality. There are 156,912 such high-\n",
      "quality PASS variants (57,728 SNPs and 99,184 indels).\n",
      "\n",
      "The FILTER column is based on two types of information. Firstly certain regions\n",
      "of the genome are considered \"non-core\". This includes sub-telomeric regions,\n",
      "centromeres and internal VAR gene clusters on chromosomes 4, 6, 7, 8 and 12.\n",
      "The apicoplast and mitochondrion are also considered non-core. All variants within\n",
      "non-core regions are considered to be low quality, and hence will not have the\n",
      "FILTER column set to PASS. The regions which are core and non-core can be found\n",
      "in the file resources/regions-20130225.bed.gz.\n",
      "\n",
      "Secondly, variants are filtered out based on a quality score called VQSLOD. All\n",
      "variants with a VQSLOD score below 0 are filtered out, i.e. will have a value of\n",
      "Low_VQSLOD in the FILTER column, rather than PASS. The VQSLOD score for each\n",
      "variant can be found in the INFO field of the VCF file. It is possible to use the\n",
      "VQSLOD score to define a more or less stringent set of variants. For example for\n",
      "a very stringent set of the highest quality variants, select only those variants\n",
      "where VQSLOD >= 6. There are 32,869 such stringent SNPs and 33,188\n",
      "such stringent indels.\n",
      "\n",
      "It is also important to note that some variants have more than two alleles. For\n",
      "example, amongst the 57,728 high quality PASS SNPs, 50,142 are biallelic. The\n",
      "remaining 7,586 high quality PASS SNPs have 3 or more alleles. Similarly, amongst\n",
      "the 99,184 high-quality PASS indels, 40,219 are biallelic. The remaining\n",
      "58,965 high quality PASS indels have 3 or more alleles.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "The VCF file contains details of {number_of_variants} discovered variants of which {number_of_snps}\n",
    "are SNPs and {number_of_indels} are indels (or multi-allelic mixtures of SNPs\n",
    "and indels). It is important to note that many of these variants are\n",
    "considered low quality. Only the variants for which the FILTER column is set\n",
    "to PASS should be considered of high quality. There are {number_of_pass_variants} such high-\n",
    "quality PASS variants ({number_of_pass_snps} SNPs and {number_of_pass_indels} indels).\n",
    "\n",
    "The FILTER column is based on two types of information. Firstly certain regions\n",
    "of the genome are considered \"non-core\". This includes sub-telomeric regions,\n",
    "centromeres and internal VAR gene clusters on chromosomes 4, 6, 7, 8 and 12.\n",
    "The apicoplast and mitochondrion are also considered non-core. All variants within\n",
    "non-core regions are considered to be low quality, and hence will not have the\n",
    "FILTER column set to PASS. The regions which are core and non-core can be found\n",
    "in the file resources/regions-20130225.bed.gz.\n",
    "\n",
    "Secondly, variants are filtered out based on a quality score called VQSLOD. All\n",
    "variants with a VQSLOD score below 0 are filtered out, i.e. will have a value of\n",
    "Low_VQSLOD in the FILTER column, rather than PASS. The VQSLOD score for each\n",
    "variant can be found in the INFO field of the VCF file. It is possible to use the\n",
    "VQSLOD score to define a more or less stringent set of variants. For example for\n",
    "a very stringent set of the highest quality variants, select only those variants\n",
    "where VQSLOD >= 6. There are {number_of_VQSLODgt6_snps} such stringent SNPs and {number_of_VQSLODgt6_indels}\n",
    "such stringent indels.\n",
    "\n",
    "It is also important to note that some variants have more than two alleles. For\n",
    "example, amongst the {number_of_pass_snps} high quality PASS SNPs, {number_of_pass_biallelic_snps} are biallelic. The\n",
    "remaining {number_of_pass_multiallelic_snps} high quality PASS SNPs have 3 or more alleles. Similarly, amongst\n",
    "the {number_of_pass_indels} high-quality PASS indels, {number_of_pass_biallelic_indels} are biallelic. The remaining\n",
    "{number_of_pass_multiallelic_indels} high quality PASS indels have 3 or more alleles.\n",
    "'''.format(\n",
    "        number_of_variants=\"{:,}\".format(int(number_of_snps[0]) + int(number_of_indels[0])),\n",
    "        number_of_snps=\"{:,}\".format(int(number_of_snps[0])),\n",
    "        number_of_indels=\"{:,}\".format(int(number_of_indels[0])),\n",
    "        number_of_pass_variants=\"{:,}\".format(int(number_of_pass_snps[0]) + int(number_of_pass_indels[0])),\n",
    "        number_of_pass_snps=\"{:,}\".format(int(number_of_pass_snps[0])),\n",
    "        number_of_pass_indels=\"{:,}\".format(int(number_of_pass_indels[0])),\n",
    "        number_of_VQSLODgt6_snps=\"{:,}\".format(int(number_of_VQSLODgt6_snps[0])),\n",
    "        number_of_VQSLODgt6_indels=\"{:,}\".format(int(number_of_VQSLODgt6_indels[0])),\n",
    "        number_of_pass_biallelic_snps=\"{:,}\".format(int(number_of_pass_biallelic_snps[0])),\n",
    "        number_of_pass_biallelic_indels=\"{:,}\".format(int(number_of_pass_biallelic_indels[0])),\n",
    "        number_of_pass_multiallelic_snps=\"{:,}\".format(int(number_of_pass_snps[0]) - int(number_of_pass_biallelic_snps[0])),\n",
    "        number_of_pass_multiallelic_indels=\"{:,}\".format(int(number_of_pass_indels[0]) - int(number_of_pass_biallelic_indels[0])),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'156,912/583,970 variants (27%) pass all filters'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{number_of_pass_variants}/{number_of_variants} variants ({pct_pass}%) pass all filters\".format(\n",
    "        number_of_variants=\"{:,}\".format(int(number_of_snps[0]) + int(number_of_indels[0])),\n",
    "        number_of_pass_variants=\"{:,}\".format(int(number_of_pass_snps[0]) + int(number_of_pass_indels[0])),\n",
    "        pct_pass=round((\n",
    "            (int(number_of_pass_snps[0]) + int(number_of_pass_indels[0])) /\n",
    "            (int(number_of_snps[0]) + int(number_of_indels[0]))\n",
    "        ) * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make all files read-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chmod: changing permissions of `/nfs/team112_internal/production/release_build/Pf/WillH_1': Operation not permitted\r\n",
      "chmod: changing permissions of `/nfs/team112_internal/production/release_build/Pf/WillH_1/Antoine_samples_vrpipe2.txt': Operation not permitted\r\n",
      "chmod: changing permissions of `/nfs/team112_internal/production/release_build/Pf/WillH_1/Antoine_samples_meta.tab': Operation not permitted\r\n"
     ]
    }
   ],
   "source": [
    "!chmod -R uga-w {RELEASE_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "PipelineSetup 'pf3kgatk_2640_genotype_gvcfs' (id 629, inactive for user dj6)\n",
    "PipelineSetup 'pf3kgatk_2640_variant_recalibration_snps' (id 630, inactive for user dj6)\n",
    "PipelineSetup 'pf3kgatk_2640_variant_recalibration_indels' (id 631, inactive for user dj6)\n",
    "PipelineSetup 'pf3kgatk_2640_select_variants_apply_recalibration_snps' (id 632, inactive for user dj6)\n",
    "PipelineSetup 'pf3kgatk_2640_select_variants_apply_recalibration_indels' (id 633, inactive for user dj6)\n",
    "PipelineSetup 'pf3kgatk_2640_variant_annotation_using_snpeff_gatk_vcf_annotate_snps' (id 634, inactive for user dj6)\n",
    "PipelineSetup 'pf3kgatk_2640_variant_annotation_using_snpeff_gatk_vcf_annotate_indels' (id 635, inactive for user dj6)\n",
    "PipelineSetup 'pf3kgatk_2640_combine_variants' (id 636, inactive for user dj6)\n",
    "PipelineSetup 'pf3kgatk_2640_variant_filtration' (id 637, inactive for user dj6)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- Add \"--MQCapForLogitJitterTransform 60\" to VariantRecalibrator\n",
    "- For SNPs use \"-an QD -an MQ -an FS -an SOR -an DP --maxGaussians 8\" in VariantRecalibrator\n",
    "- For indels use \"-an QD -an FS -an SOR -an DP --maxGaussians 4\" in VariantRecalibrator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.4.3 |Anaconda 2.2.0 (64-bit)| (default, Mar  6 2015, 12:03:53) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "numpy 1.9.2\n",
      "scipy 0.15.1\n",
      "pandas 0.15.2\n",
      "numexpr 2.3.1\n",
      "pysam 0.8.3\n",
      "petl 1.0.11\n",
      "petlx 1.0.3\n",
      "vcf 0.6.7\n",
      "h5py 2.4.0\n",
      "tables 3.1.1\n",
      "vcfplt 0.8\n"
     ]
    }
   ],
   "source": [
    "# %run standard_imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
